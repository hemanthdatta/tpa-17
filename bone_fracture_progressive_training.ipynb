{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b638aa",
   "metadata": {},
   "source": [
    "# Three-Stage Progressive Training for Bone Fracture Classification\n",
    "\n",
    "## Overview\n",
    "This notebook implements a comprehensive three-stage training approach:\n",
    "\n",
    "### Stage 1: Linear Probing\n",
    "- Extract features from frozen DINOv2 backbone\n",
    "- Train classification heads of varying depths\n",
    "- Select best performing architecture\n",
    "\n",
    "### Stage 2: Partial Fine-Tuning\n",
    "- Freeze trained classifier\n",
    "- Selectively train backbone layers (LoRA, top/bottom/middle layers)\n",
    "- Apply aggressive data augmentation to reduce overfitting\n",
    "\n",
    "### Stage 3: Full Fine-Tuning\n",
    "- Unfreeze all layers\n",
    "- Train entire model end-to-end with very low learning rate\n",
    "- Final optimization for best performance\n",
    "\n",
    "**Dataset**: Bone Break Classification (X-ray Images)  \n",
    "**Approach**: Progressive unfreezing with balanced class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eba1ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "Device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c5d1f",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "Load all images from both Train and Test directories, merge them, and create a stratified 60/20/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd9c64b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from all directories...\n",
      "\n",
      "Total images collected: 1129\n",
      "Number of classes: 10\n",
      "\n",
      "Class names: ['Avulsion fracture', 'Comminuted fracture', 'Fracture Dislocation', 'Greenstick fracture', 'Hairline Fracture', 'Impacted fracture', 'Longitudinal fracture', 'Oblique fracture', 'Pathological fracture', 'Spiral Fracture']\n",
      "\n",
      "Class distribution:\n",
      "  Avulsion fracture: 123 images\n",
      "  Comminuted fracture: 148 images\n",
      "  Fracture Dislocation: 156 images\n",
      "  Greenstick fracture: 122 images\n",
      "  Hairline Fracture: 111 images\n",
      "  Impacted fracture: 84 images\n",
      "  Longitudinal fracture: 80 images\n",
      "  Oblique fracture: 85 images\n",
      "  Pathological fracture: 134 images\n",
      "  Spiral Fracture: 86 images\n"
     ]
    }
   ],
   "source": [
    "# Dataset paths\n",
    "DATASET_ROOT = \"/kaggle/input/bone-break-classification-image-dataset/Bone Break Classification/Bone Break Classification\"\n",
    "\n",
    "# Collect all image paths and labels\n",
    "all_image_paths = []\n",
    "all_labels = []\n",
    "class_names = sorted(os.listdir(DATASET_ROOT))\n",
    "\n",
    "print(\"Loading dataset from all directories...\")\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(DATASET_ROOT, class_name)\n",
    "    \n",
    "    # Collect from Train directory\n",
    "    train_path = os.path.join(class_path, \"Train\")\n",
    "    if os.path.exists(train_path):\n",
    "        for img_name in os.listdir(train_path):\n",
    "            img_path = os.path.join(train_path, img_name)\n",
    "            if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                all_image_paths.append(img_path)\n",
    "                all_labels.append(class_name)\n",
    "    \n",
    "    # Collect from Test directory\n",
    "    test_path = os.path.join(class_path, \"Test\")\n",
    "    if os.path.exists(test_path):\n",
    "        for img_name in os.listdir(test_path):\n",
    "            img_path = os.path.join(test_path, img_name)\n",
    "            if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                all_image_paths.append(img_path)\n",
    "                all_labels.append(class_name)\n",
    "\n",
    "print(f\"\\nTotal images collected: {len(all_image_paths)}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"\\nClass names: {class_names}\")\n",
    "\n",
    "# Show class distribution\n",
    "class_counts = Counter(all_labels)\n",
    "print(\"\\nClass distribution:\")\n",
    "for class_name in class_names:\n",
    "    print(f\"  {class_name}: {class_counts[class_name]} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64bfeeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STRATIFIED DATA SPLIT (60/20/20)\n",
      "============================================================\n",
      "\n",
      "Train set: 677 images (60.0%)\n",
      "Val set:   226 images (20.0%)\n",
      "Test set:  226 images (20.0%)\n",
      "\n",
      "Class distribution per split:\n",
      "\n",
      "Train:\n",
      "  Avulsion fracture: 74 images\n",
      "  Comminuted fracture: 89 images\n",
      "  Fracture Dislocation: 93 images\n",
      "  Greenstick fracture: 73 images\n",
      "  Hairline Fracture: 67 images\n",
      "  Impacted fracture: 50 images\n",
      "  Longitudinal fracture: 48 images\n",
      "  Oblique fracture: 51 images\n",
      "  Pathological fracture: 80 images\n",
      "  Spiral Fracture: 52 images\n",
      "\n",
      "Val:\n",
      "  Avulsion fracture: 25 images\n",
      "  Comminuted fracture: 30 images\n",
      "  Fracture Dislocation: 31 images\n",
      "  Greenstick fracture: 24 images\n",
      "  Hairline Fracture: 22 images\n",
      "  Impacted fracture: 17 images\n",
      "  Longitudinal fracture: 16 images\n",
      "  Oblique fracture: 17 images\n",
      "  Pathological fracture: 27 images\n",
      "  Spiral Fracture: 17 images\n",
      "\n",
      "Test:\n",
      "  Avulsion fracture: 24 images\n",
      "  Comminuted fracture: 29 images\n",
      "  Fracture Dislocation: 32 images\n",
      "  Greenstick fracture: 25 images\n",
      "  Hairline Fracture: 22 images\n",
      "  Impacted fracture: 17 images\n",
      "  Longitudinal fracture: 16 images\n",
      "  Oblique fracture: 17 images\n",
      "  Pathological fracture: 27 images\n",
      "  Spiral Fracture: 17 images\n"
     ]
    }
   ],
   "source": [
    "# Create label encoding\n",
    "label_to_idx = {label: idx for idx, label in enumerate(class_names)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "numeric_labels = [label_to_idx[label] for label in all_labels]\n",
    "\n",
    "# Perform stratified 60/20/20 split\n",
    "# First split: 60% train, 40% temp\n",
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "    all_image_paths, numeric_labels, \n",
    "    test_size=0.4, \n",
    "    stratify=numeric_labels, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: 40% temp -> 20% val, 20% test\n",
    "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "    temp_paths, temp_labels,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATIFIED DATA SPLIT (60/20/20)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTrain set: {len(train_paths)} images ({len(train_paths)/len(all_image_paths)*100:.1f}%)\")\n",
    "print(f\"Val set:   {len(val_paths)} images ({len(val_paths)/len(all_image_paths)*100:.1f}%)\")\n",
    "print(f\"Test set:  {len(test_paths)} images ({len(test_paths)/len(all_image_paths)*100:.1f}%)\")\n",
    "\n",
    "# Verify class balance\n",
    "print(\"\\nClass distribution per split:\")\n",
    "for split_name, split_labels in [(\"Train\", train_labels), (\"Val\", val_labels), (\"Test\", test_labels)]:\n",
    "    counts = Counter(split_labels)\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    for idx in sorted(counts.keys()):\n",
    "        class_name = idx_to_label[idx]\n",
    "        print(f\"  {class_name}: {counts[idx]} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67505cdb",
   "metadata": {},
   "source": [
    "## 2. Dataset and DataLoader Setup\n",
    "\n",
    "Create custom dataset class with configurable augmentation for different training stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e9cc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforms defined:\n",
      "  - basic_transform: For Stage 1 & 3 (light augmentation)\n",
      "  - heavy_transform: For Stage 2 (aggressive augmentation)\n",
      "  - eval_transform: For validation/test (no augmentation)\n"
     ]
    }
   ],
   "source": [
    "class BoneFractureDataset(Dataset):\n",
    "    \"\"\"Custom dataset for bone fracture classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "# Stage 1 & 3: Basic augmentation\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomRotation(degrees=5),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Stage 2: Heavy augmentation\n",
    "heavy_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test: No augmentation\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Transforms defined:\")\n",
    "print(\"  - basic_transform: For Stage 1 & 3 (light augmentation)\")\n",
    "print(\"  - heavy_transform: For Stage 2 (aggressive augmentation)\")\n",
    "print(\"  - eval_transform: For validation/test (no augmentation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae6c5be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets created:\n",
      "  Train: 677 samples\n",
      "  Val:   226 samples\n",
      "  Test:  226 samples\n",
      "\n",
      "DataLoaders created with batch_size=64\n",
      "  Train batches: 11\n",
      "  Val batches:   4\n",
      "  Test batches:  4\n"
     ]
    }
   ],
   "source": [
    "# Create datasets (will create dataloaders later per stage)\n",
    "train_dataset = BoneFractureDataset(train_paths, train_labels, transform=basic_transform)\n",
    "val_dataset = BoneFractureDataset(val_paths, val_labels, transform=eval_transform)\n",
    "test_dataset = BoneFractureDataset(test_paths, test_labels, transform=eval_transform)\n",
    "\n",
    "print(f\"\\nDatasets created:\")\n",
    "print(f\"  Train: {len(train_dataset)} samples\")\n",
    "print(f\"  Val:   {len(val_dataset)} samples\")\n",
    "print(f\"  Test:  {len(test_dataset)} samples\")\n",
    "\n",
    "# Create dataloaders (without num_workers to avoid multiprocessing issues)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "print(f\"\\nDataLoaders created with batch_size={batch_size}\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches:   {len(val_loader)}\")\n",
    "print(f\"  Test batches:  {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e27700",
   "metadata": {},
   "source": [
    "## 3. Load Pretrained Backbones\n",
    "\n",
    "Load CLIP-B (Base) and DINOv2-Small models as feature extractors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6617203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DINOv2 Small model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vits14/dinov2_vits14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vits14_pretrain.pth\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vits14/dinov2_vits14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vits14_pretrain.pth\n",
      "100%|██████████| 84.2M/84.2M [00:00<00:00, 218MB/s] \n",
      "100%|██████████| 84.2M/84.2M [00:00<00:00, 218MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DINOv2 Small loaded - Feature dimension: 384\n",
      "  Parameters: 22,056,576\n"
     ]
    }
   ],
   "source": [
    "# Load DINOv2 Small model\n",
    "print(\"Loading DINOv2 Small model...\")\n",
    "dinov2_small = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
    "dinov2_small.eval()\n",
    "dinov2_small = dinov2_small.cuda()\n",
    "\n",
    "# Get feature dimension\n",
    "with torch.no_grad():\n",
    "    dummy_input = torch.randn(1, 3, 224, 224).cuda()\n",
    "    dinov2_features = dinov2_small(dummy_input)\n",
    "    dinov2_dim = dinov2_features.shape[1]\n",
    "\n",
    "print(f\"✓ DINOv2 Small loaded - Feature dimension: {dinov2_dim}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in dinov2_small.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3318ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install open_clip_torch for CLIP model\n",
    "%pip install -q open_clip_torch\n",
    "print(\"✓ open_clip_torch installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dac1f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CLIP Base model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4577a7d3e14f9db253727873a74ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CLIP Base loaded - Feature dimension: 512\n",
      "  Parameters: 86,192,640\n"
     ]
    }
   ],
   "source": [
    "# Load CLIP Base model using open_clip\n",
    "print(\"Loading CLIP Base model...\")\n",
    "import open_clip\n",
    "\n",
    "clip_model, _, clip_preprocess = open_clip.create_model_and_transforms('ViT-B-16', pretrained='openai')\n",
    "clip_model = clip_model.cuda()\n",
    "clip_model.eval()\n",
    "\n",
    "# Get CLIP visual encoder and feature dimension\n",
    "clip_visual = clip_model.visual\n",
    "with torch.no_grad():\n",
    "    dummy_input = torch.randn(1, 3, 224, 224).cuda()\n",
    "    clip_features = clip_visual(dummy_input)\n",
    "    clip_dim = clip_features.shape[1]\n",
    "\n",
    "print(f\"✓ CLIP Base loaded - Feature dimension: {clip_dim}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in clip_visual.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116bbc09",
   "metadata": {},
   "source": [
    "## 4. Define Multiple Classifier Architectures\n",
    "\n",
    "Create various classifier heads with different depths and configurations to test during Stage 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ef42650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier architectures defined:\n",
      "  1-Layer: input -> output\n",
      "  2-Layer: input -> 512 -> output\n",
      "  3-Layer: input -> 512 -> 256 -> output\n",
      "  4-Layer: input -> 512 -> 256 -> 128 -> output\n"
     ]
    }
   ],
   "source": [
    "class Classifier1Layer(nn.Module):\n",
    "    \"\"\"Simple 1-layer linear classifier\"\"\"\n",
    "    def __init__(self, input_dim, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class Classifier2Layer(nn.Module):\n",
    "    \"\"\"2-layer MLP with BatchNorm and Dropout\"\"\"\n",
    "    def __init__(self, input_dim, num_classes=10, hidden_dim=512, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Classifier3Layer(nn.Module):\n",
    "    \"\"\"3-layer deep MLP with BatchNorm and Dropout\"\"\"\n",
    "    def __init__(self, input_dim, num_classes=10, hidden_dim1=512, hidden_dim2=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Classifier4Layer(nn.Module):\n",
    "    \"\"\"4-layer very deep MLP with BatchNorm and Dropout\"\"\"\n",
    "    def __init__(self, input_dim, num_classes=10, hidden_dims=[512, 256, 128], dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dims[0])\n",
    "        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dims[1])\n",
    "        self.fc3 = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dims[2])\n",
    "        self.fc4 = nn.Linear(hidden_dims[2], num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "print(\"Classifier architectures defined:\")\n",
    "print(\"  1-Layer: input -> output\")\n",
    "print(\"  2-Layer: input -> 512 -> output\")\n",
    "print(\"  3-Layer: input -> 512 -> 256 -> output\")\n",
    "print(\"  4-Layer: input -> 512 -> 256 -> 128 -> output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b6508",
   "metadata": {},
   "source": [
    "## 5. Precompute Features\n",
    "\n",
    "Extract features once from both backbones to speed up classifier training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39d2d335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction and training functions defined.\n"
     ]
    }
   ],
   "source": [
    "def extract_features(backbone, dataloader, backbone_name=\"backbone\"):\n",
    "    \"\"\"Extract features from a frozen backbone\"\"\"\n",
    "    device = torch.device('cuda')\n",
    "    backbone.eval()\n",
    "    \n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(f\"Extracting features from {backbone_name}...\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=f\"Extracting {backbone_name} features\"):\n",
    "            images = images.to(device)\n",
    "            features = backbone(images)\n",
    "            all_features.append(features.cpu())\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    print(f\"✓ Extracted {all_features.shape[0]} feature vectors of dim {all_features.shape[1]}\")\n",
    "    return all_features, all_labels\n",
    "\n",
    "\n",
    "def train_classifier_on_features(classifier, train_features, train_labels, val_features, val_labels, \n",
    "                                 epochs=20, lr=1e-3, batch_size=64):\n",
    "    \"\"\"Train a classifier on precomputed features\"\"\"\n",
    "    device = torch.device('cuda')\n",
    "    classifier = classifier.cuda()\n",
    "    \n",
    "    # Create tensor datasets\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "    val_dataset = torch.utils.data.TensorDataset(val_features, val_labels)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(classifier.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        classifier.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward through classifier\n",
    "            outputs = classifier(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Stats\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        \n",
    "        # Validation\n",
    "        classifier.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = classifier(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}% (Best: {best_val_acc:.2f}% @ Epoch {best_epoch})\")\n",
    "    \n",
    "    print(f\"Final - Best Val Acc: {best_val_acc:.2f}% @ Epoch {best_epoch}\")\n",
    "    return classifier, best_val_acc, history\n",
    "\n",
    "\n",
    "def evaluate_classifier_on_features(classifier, test_features, test_labels, batch_size=64):\n",
    "    \"\"\"Evaluate classifier on precomputed features\"\"\"\n",
    "    device = torch.device('cuda')\n",
    "    classifier.eval()\n",
    "    \n",
    "    test_dataset = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = classifier(features)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    test_acc = 100. * correct / total\n",
    "    return test_acc\n",
    "\n",
    "print(\"Feature extraction and training functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29e8d3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXTRACTING FEATURES FROM BOTH BACKBONES\n",
      "================================================================================\n",
      "Extracting features from DINOv2-Small...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856f086da1f94148ade32bd0c11df52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting DINOv2-Small features:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 677 feature vectors of dim 384\n",
      "Extracting features from DINOv2-Small...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7627409c2c8240a58c2481700d04e89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting DINOv2-Small features:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 226 feature vectors of dim 384\n",
      "Extracting features from DINOv2-Small...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882793b32bf3493482f49c8147d3296f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting DINOv2-Small features:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 226 feature vectors of dim 384\n",
      "\n",
      "Extracting features from CLIP-Base...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19be4dc13dce4c838115fe049e711b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting CLIP-Base features:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 677 feature vectors of dim 512\n",
      "Extracting features from CLIP-Base...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca936d457a2349cc9e1f4f5b6e780f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting CLIP-Base features:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 226 feature vectors of dim 512\n",
      "Extracting features from CLIP-Base...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dba0f3339cf4d8e9dfae3679fc9243e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting CLIP-Base features:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 226 feature vectors of dim 512\n",
      "\n",
      "================================================================================\n",
      "FEATURE EXTRACTION COMPLETE\n",
      "================================================================================\n",
      "DINOv2-Small features: torch.Size([677, 384])\n",
      "CLIP-Base features: torch.Size([677, 512])\n"
     ]
    }
   ],
   "source": [
    "# Extract features from both backbones\n",
    "print(\"=\"*80)\n",
    "print(\"EXTRACTING FEATURES FROM BOTH BACKBONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# DINOv2 features\n",
    "dinov2_train_features, dinov2_train_labels = extract_features(dinov2_small, train_loader, \"DINOv2-Small\")\n",
    "dinov2_val_features, dinov2_val_labels = extract_features(dinov2_small, val_loader, \"DINOv2-Small\")\n",
    "dinov2_test_features, dinov2_test_labels = extract_features(dinov2_small, test_loader, \"DINOv2-Small\")\n",
    "\n",
    "print()\n",
    "\n",
    "# CLIP features\n",
    "clip_train_features, clip_train_labels = extract_features(clip_visual, train_loader, \"CLIP-Base\")\n",
    "clip_val_features, clip_val_labels = extract_features(clip_visual, val_loader, \"CLIP-Base\")\n",
    "clip_test_features, clip_test_labels = extract_features(clip_visual, test_loader, \"CLIP-Base\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE EXTRACTION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"DINOv2-Small features: {dinov2_train_features.shape}\")\n",
    "print(f\"CLIP-Base features: {clip_train_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0a234",
   "metadata": {},
   "source": [
    "## 6. Stage 1: Linear Probing\n",
    "\n",
    "Train multiple classifier heads on precomputed features. Test all 8 combinations:\n",
    "- **Backbones**: DINOv2-Small, CLIP-Base  \n",
    "- **Classifiers**: 1-layer, 2-layer, 3-layer, 4-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "440b0d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clip_visual' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_79/2488506767.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m backbone_configs = [\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"DINOv2-Small\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdinov2_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdinov2_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"CLIP-Base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_visual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m ]\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clip_visual' is not defined"
     ]
    }
   ],
   "source": [
    "# Store results for comparison\n",
    "stage1_results = []\n",
    "\n",
    "# Define configurations to test\n",
    "classifier_configs = [\n",
    "    (\"1-Layer\", Classifier1Layer),\n",
    "    (\"2-Layer\", Classifier2Layer),\n",
    "    (\"3-Layer\", Classifier3Layer),\n",
    "    (\"4-Layer\", Classifier4Layer)\n",
    "]\n",
    "\n",
    "backbone_configs = [\n",
    "    (\"DINOv2-Small\", dinov2_small, dinov2_dim),\n",
    "    (\"CLIP-Base\", clip_visual, clip_dim)\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STAGE 1: LINEAR PROBING - Training all classifier configurations\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal configurations to test: {len(classifier_configs) * len(backbone_configs)}\")\n",
    "print(f\"Training epochs per configuration: 20\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a5a9e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 1: LINEAR PROBING - Training all classifier configurations\n",
      "================================================================================\n",
      "\n",
      "Total configurations to test: 8\n",
      "Training epochs per configuration: 20\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BACKBONE: DINOv2-Small (Feature dim: 384)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Testing 1-Layer Classifier ---\n",
      "Epoch 1/20 - Train Loss: 2.5283, Train Acc: 14.48%, Val Loss: 2.3125, Val Acc: 19.91% (Best: 19.91% @ Epoch 1)\n",
      "Epoch 5/20 - Train Loss: 1.8312, Train Acc: 38.11%, Val Loss: 2.0671, Val Acc: 30.09% (Best: 30.09% @ Epoch 5)\n",
      "Epoch 10/20 - Train Loss: 1.5662, Train Acc: 49.34%, Val Loss: 1.9818, Val Acc: 33.19% (Best: 33.19% @ Epoch 10)\n",
      "Epoch 15/20 - Train Loss: 1.4532, Train Acc: 54.51%, Val Loss: 1.9617, Val Acc: 36.28% (Best: 36.28% @ Epoch 15)\n",
      "Epoch 20/20 - Train Loss: 1.4285, Train Acc: 55.54%, Val Loss: 1.9619, Val Acc: 33.63% (Best: 36.28% @ Epoch 15)\n",
      "Final - Best Val Acc: 36.28% @ Epoch 15\n",
      "\n",
      "✓ DINOv2-Small + 1-Layer:\n",
      "  Best Val Acc: 36.28%\n",
      "  Test Acc: 35.40%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Testing 2-Layer Classifier ---\n",
      "Epoch 1/20 - Train Loss: 2.2513, Train Acc: 19.05%, Val Loss: 2.0834, Val Acc: 28.32% (Best: 28.32% @ Epoch 1)\n",
      "Epoch 5/20 - Train Loss: 0.9672, Train Acc: 76.81%, Val Loss: 1.8459, Val Acc: 38.94% (Best: 38.94% @ Epoch 4)\n",
      "Epoch 10/20 - Train Loss: 0.4324, Train Acc: 94.98%, Val Loss: 1.8507, Val Acc: 39.38% (Best: 41.59% @ Epoch 9)\n",
      "Epoch 15/20 - Train Loss: 0.2752, Train Acc: 98.52%, Val Loss: 1.8801, Val Acc: 40.71% (Best: 41.59% @ Epoch 9)\n",
      "Epoch 20/20 - Train Loss: 0.2458, Train Acc: 99.41%, Val Loss: 1.8858, Val Acc: 40.71% (Best: 41.59% @ Epoch 9)\n",
      "Final - Best Val Acc: 41.59% @ Epoch 9\n",
      "\n",
      "✓ DINOv2-Small + 2-Layer:\n",
      "  Best Val Acc: 41.59%\n",
      "  Test Acc: 44.69%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Testing 3-Layer Classifier ---\n",
      "Epoch 1/20 - Train Loss: 2.2506, Train Acc: 19.05%, Val Loss: 2.1055, Val Acc: 25.22% (Best: 25.22% @ Epoch 1)\n",
      "Epoch 5/20 - Train Loss: 1.0218, Train Acc: 75.33%, Val Loss: 1.8262, Val Acc: 39.82% (Best: 39.82% @ Epoch 5)\n",
      "Epoch 10/20 - Train Loss: 0.4066, Train Acc: 95.27%, Val Loss: 1.8372, Val Acc: 41.59% (Best: 41.59% @ Epoch 7)\n",
      "Epoch 15/20 - Train Loss: 0.2026, Train Acc: 99.11%, Val Loss: 1.8968, Val Acc: 39.38% (Best: 42.04% @ Epoch 12)\n",
      "Epoch 20/20 - Train Loss: 0.1791, Train Acc: 99.56%, Val Loss: 1.9021, Val Acc: 39.38% (Best: 42.04% @ Epoch 12)\n",
      "Final - Best Val Acc: 42.04% @ Epoch 12\n",
      "\n",
      "✓ DINOv2-Small + 3-Layer:\n",
      "  Best Val Acc: 42.04%\n",
      "  Test Acc: 43.81%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Testing 4-Layer Classifier ---\n",
      "Epoch 1/20 - Train Loss: 2.3146, Train Acc: 15.81%, Val Loss: 2.2059, Val Acc: 26.55% (Best: 26.55% @ Epoch 1)\n",
      "Epoch 5/20 - Train Loss: 1.4406, Train Acc: 58.79%, Val Loss: 1.8635, Val Acc: 38.50% (Best: 38.50% @ Epoch 5)\n",
      "Epoch 10/20 - Train Loss: 0.7788, Train Acc: 82.87%, Val Loss: 1.8126, Val Acc: 38.50% (Best: 42.48% @ Epoch 9)\n",
      "Epoch 15/20 - Train Loss: 0.4815, Train Acc: 92.76%, Val Loss: 1.7763, Val Acc: 42.04% (Best: 42.92% @ Epoch 11)\n",
      "Epoch 20/20 - Train Loss: 0.4458, Train Acc: 93.06%, Val Loss: 1.7741, Val Acc: 42.48% (Best: 44.25% @ Epoch 18)\n",
      "Final - Best Val Acc: 44.25% @ Epoch 18\n",
      "\n",
      "✓ DINOv2-Small + 4-Layer:\n",
      "  Best Val Acc: 44.25%\n",
      "  Test Acc: 42.92%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "BACKBONE: CLIP-Base (Feature dim: 512)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Testing 1-Layer Classifier ---\n",
      "Epoch 1/20 - Train Loss: 2.2899, Train Acc: 12.85%, Val Loss: 2.2456, Val Acc: 19.03% (Best: 19.03% @ Epoch 1)\n",
      "Epoch 5/20 - Train Loss: 2.0950, Train Acc: 29.39%, Val Loss: 2.1311, Val Acc: 27.88% (Best: 27.88% @ Epoch 4)\n",
      "Epoch 10/20 - Train Loss: 1.9952, Train Acc: 33.53%, Val Loss: 2.0830, Val Acc: 28.76% (Best: 30.53% @ Epoch 8)\n",
      "Epoch 15/20 - Train Loss: 1.9467, Train Acc: 35.16%, Val Loss: 2.0677, Val Acc: 28.32% (Best: 30.53% @ Epoch 8)\n",
      "Epoch 20/20 - Train Loss: 1.9391, Train Acc: 36.63%, Val Loss: 2.0649, Val Acc: 28.76% (Best: 30.53% @ Epoch 8)\n",
      "Final - Best Val Acc: 30.53% @ Epoch 8\n",
      "\n",
      "✓ CLIP-Base + 1-Layer:\n",
      "  Best Val Acc: 30.53%\n",
      "  Test Acc: 27.88%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Testing 2-Layer Classifier ---\n",
      "Epoch 1/20 - Train Loss: 2.1730, Train Acc: 22.16%, Val Loss: 2.1688, Val Acc: 30.09% (Best: 30.09% @ Epoch 1)\n",
      "Epoch 5/20 - Train Loss: 1.0923, Train Acc: 70.75%, Val Loss: 1.8927, Val Acc: 33.19% (Best: 33.19% @ Epoch 5)\n",
      "Epoch 10/20 - Train Loss: 0.5387, Train Acc: 91.58%, Val Loss: 1.9707, Val Acc: 33.19% (Best: 34.07% @ Epoch 6)\n",
      "Epoch 15/20 - Train Loss: 0.3271, Train Acc: 97.64%, Val Loss: 2.0526, Val Acc: 34.96% (Best: 34.96% @ Epoch 15)\n",
      "Epoch 20/20 - Train Loss: 0.2736, Train Acc: 98.97%, Val Loss: 2.0736, Val Acc: 34.96% (Best: 34.96% @ Epoch 15)\n",
      "Final - Best Val Acc: 34.96% @ Epoch 15\n",
      "\n",
      "✓ CLIP-Base + 2-Layer:\n",
      "  Best Val Acc: 34.96%\n",
      "  Test Acc: 34.51%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Testing 3-Layer Classifier ---\n",
      "Epoch 1/20 - Train Loss: 2.2008, Train Acc: 19.94%, Val Loss: 2.2178, Val Acc: 22.12% (Best: 22.12% @ Epoch 1)\n",
      "Epoch 5/20 - Train Loss: 1.2315, Train Acc: 62.78%, Val Loss: 1.9170, Val Acc: 30.53% (Best: 31.86% @ Epoch 4)\n",
      "Epoch 10/20 - Train Loss: 0.6053, Train Acc: 87.74%, Val Loss: 2.0524, Val Acc: 30.53% (Best: 31.86% @ Epoch 4)\n",
      "Epoch 15/20 - Train Loss: 0.3388, Train Acc: 96.31%, Val Loss: 2.1646, Val Acc: 31.42% (Best: 35.40% @ Epoch 13)\n",
      "Epoch 20/20 - Train Loss: 0.2715, Train Acc: 98.23%, Val Loss: 2.1454, Val Acc: 32.74% (Best: 35.40% @ Epoch 13)\n",
      "Final - Best Val Acc: 35.40% @ Epoch 13\n",
      "\n",
      "✓ CLIP-Base + 3-Layer:\n",
      "  Best Val Acc: 35.40%\n",
      "  Test Acc: 34.07%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Testing 4-Layer Classifier ---\n",
      "Epoch 1/20 - Train Loss: 2.3069, Train Acc: 14.03%, Val Loss: 2.2880, Val Acc: 9.29% (Best: 9.29% @ Epoch 1)\n",
      "Epoch 5/20 - Train Loss: 1.6505, Train Acc: 47.12%, Val Loss: 1.9671, Val Acc: 30.53% (Best: 30.53% @ Epoch 5)\n",
      "Epoch 10/20 - Train Loss: 1.1238, Train Acc: 70.01%, Val Loss: 1.9551, Val Acc: 31.86% (Best: 37.61% @ Epoch 7)\n",
      "Epoch 15/20 - Train Loss: 0.7739, Train Acc: 80.95%, Val Loss: 1.9449, Val Acc: 32.30% (Best: 37.61% @ Epoch 7)\n",
      "Epoch 20/20 - Train Loss: 0.6936, Train Acc: 86.12%, Val Loss: 1.9396, Val Acc: 31.86% (Best: 37.61% @ Epoch 7)\n",
      "Final - Best Val Acc: 37.61% @ Epoch 7\n",
      "\n",
      "✓ CLIP-Base + 4-Layer:\n",
      "  Best Val Acc: 37.61%\n",
      "  Test Acc: 30.97%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "STAGE 1 COMPLETE - All configurations trained\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Store results for comparison\n",
    "stage1_results = []\n",
    "\n",
    "# Define feature sets\n",
    "feature_sets = [\n",
    "    (\"DINOv2-Small\", dinov2_train_features, dinov2_train_labels, dinov2_val_features, dinov2_val_labels, \n",
    "     dinov2_test_features, dinov2_test_labels, dinov2_dim),\n",
    "    (\"CLIP-Base\", clip_train_features, clip_train_labels, clip_val_features, clip_val_labels,\n",
    "     clip_test_features, clip_test_labels, clip_dim)\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STAGE 1: LINEAR PROBING - Training all classifier configurations\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal configurations to test: {len(classifier_configs) * len(feature_sets)}\")\n",
    "print(f\"Training epochs per configuration: 20\\n\")\n",
    "\n",
    "# Train all configurations\n",
    "for backbone_name, train_feat, train_lbl, val_feat, val_lbl, test_feat, test_lbl, feature_dim in feature_sets:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"BACKBONE: {backbone_name} (Feature dim: {feature_dim})\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for classifier_name, ClassifierClass in classifier_configs:\n",
    "        print(f\"\\n--- Testing {classifier_name} Classifier ---\")\n",
    "        \n",
    "        # Create classifier\n",
    "        if classifier_name == \"1-Layer\":\n",
    "            classifier = ClassifierClass(feature_dim, num_classes=10)\n",
    "        elif classifier_name == \"2-Layer\":\n",
    "            classifier = ClassifierClass(feature_dim, num_classes=10, hidden_dim=512, dropout=0.3)\n",
    "        elif classifier_name == \"3-Layer\":\n",
    "            classifier = ClassifierClass(feature_dim, num_classes=10, hidden_dim1=512, hidden_dim2=256, dropout=0.3)\n",
    "        else:  # 4-Layer\n",
    "            classifier = ClassifierClass(feature_dim, num_classes=10, hidden_dims=[512, 256, 128], dropout=0.3)\n",
    "        \n",
    "        # Train on precomputed features\n",
    "        trained_classifier, best_val_acc, history = train_classifier_on_features(\n",
    "            classifier=classifier,\n",
    "            train_features=train_feat,\n",
    "            train_labels=train_lbl,\n",
    "            val_features=val_feat,\n",
    "            val_labels=val_lbl,\n",
    "            epochs=20,\n",
    "            lr=1e-3,\n",
    "            batch_size=64\n",
    "        )\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_acc = evaluate_classifier_on_features(trained_classifier, test_feat, test_lbl, batch_size=64)\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'backbone': backbone_name,\n",
    "            'classifier': classifier_name,\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'test_acc': test_acc,\n",
    "            'history': history,\n",
    "            'model': trained_classifier\n",
    "        }\n",
    "        stage1_results.append(result)\n",
    "        \n",
    "        print(f\"\\n✓ {backbone_name} + {classifier_name}:\")\n",
    "        print(f\"  Best Val Acc: {best_val_acc:.2f}%\")\n",
    "        print(f\"  Test Acc: {test_acc:.2f}%\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STAGE 1 COMPLETE - All configurations trained\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f60c1821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STAGE 1 RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "     Backbone Classifier Best Val Acc (%) Test Acc (%)\n",
      "DINOv2-Small    1-Layer            36.28        35.40\n",
      "DINOv2-Small    2-Layer            41.59        44.69\n",
      "DINOv2-Small    3-Layer            42.04        43.81\n",
      "DINOv2-Small    4-Layer            44.25        42.92\n",
      "   CLIP-Base    1-Layer            30.53        27.88\n",
      "   CLIP-Base    2-Layer            34.96        34.51\n",
      "   CLIP-Base    3-Layer            35.40        34.07\n",
      "   CLIP-Base    4-Layer            37.61        30.97\n",
      "\n",
      "================================================================================\n",
      "BEST CONFIGURATION:\n",
      "  DINOv2-Small + 2-Layer\n",
      "  Val Acc: 41.59%\n",
      "  Test Acc: 44.69%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display results summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 1 RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'Backbone': r['backbone'],\n",
    "        'Classifier': r['classifier'],\n",
    "        'Best Val Acc (%)': f\"{r['best_val_acc']:.2f}\",\n",
    "        'Test Acc (%)': f\"{r['test_acc']:.2f}\"\n",
    "    }\n",
    "    for r in stage1_results\n",
    "])\n",
    "\n",
    "print(\"\\n\", results_df.to_string(index=False))\n",
    "\n",
    "# Find best configuration\n",
    "best_result = max(stage1_results, key=lambda x: x['test_acc'])\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"BEST CONFIGURATION:\")\n",
    "print(f\"  {best_result['backbone']} + {best_result['classifier']}\")\n",
    "print(f\"  Val Acc: {best_result['best_val_acc']:.2f}%\")\n",
    "print(f\"  Test Acc: {best_result['test_acc']:.2f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7d5c22",
   "metadata": {},
   "source": [
    "## 6.1 Retrain Best Configurations with Higher Epochs\n",
    "\n",
    "Retrain top performers with 50 epochs for better convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "796bdd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RETRAINING BEST CONFIGURATIONS WITH 50 EPOCHS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Training: DINOv2-Small + 2-Layer (50 epochs)\n",
      "================================================================================\n",
      "Epoch 1/50 - Train Loss: 2.2280, Train Acc: 17.28%, Val Loss: 2.1240, Val Acc: 28.76% (Best: 28.76% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 0.9185, Train Acc: 77.99%, Val Loss: 1.8368, Val Acc: 37.61% (Best: 38.05% @ Epoch 2)\n",
      "Epoch 10/50 - Train Loss: 0.3731, Train Acc: 96.16%, Val Loss: 1.8562, Val Acc: 39.82% (Best: 40.71% @ Epoch 7)\n",
      "Epoch 15/50 - Train Loss: 0.1661, Train Acc: 99.70%, Val Loss: 1.9572, Val Acc: 41.59% (Best: 42.92% @ Epoch 12)\n",
      "Epoch 20/50 - Train Loss: 0.0752, Train Acc: 100.00%, Val Loss: 2.0497, Val Acc: 41.15% (Best: 42.92% @ Epoch 12)\n",
      "Epoch 25/50 - Train Loss: 0.0562, Train Acc: 99.85%, Val Loss: 2.1071, Val Acc: 39.82% (Best: 42.92% @ Epoch 12)\n",
      "Epoch 30/50 - Train Loss: 0.0410, Train Acc: 100.00%, Val Loss: 2.1572, Val Acc: 42.48% (Best: 42.92% @ Epoch 12)\n",
      "Epoch 35/50 - Train Loss: 0.0315, Train Acc: 100.00%, Val Loss: 2.1751, Val Acc: 42.04% (Best: 42.92% @ Epoch 12)\n",
      "Epoch 40/50 - Train Loss: 0.0297, Train Acc: 100.00%, Val Loss: 2.2118, Val Acc: 41.15% (Best: 42.92% @ Epoch 12)\n",
      "Epoch 45/50 - Train Loss: 0.0295, Train Acc: 100.00%, Val Loss: 2.2037, Val Acc: 41.15% (Best: 42.92% @ Epoch 12)\n",
      "Epoch 50/50 - Train Loss: 0.0272, Train Acc: 100.00%, Val Loss: 2.2123, Val Acc: 41.59% (Best: 42.92% @ Epoch 12)\n",
      "Final - Best Val Acc: 42.92% @ Epoch 12\n",
      "\n",
      "✓ DINOv2-Small + 2-Layer (50 epochs):\n",
      "  Best Val Acc: 42.92%\n",
      "  Test Acc: 44.69%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Training: DINOv2-Small + 3-Layer (50 epochs)\n",
      "================================================================================\n",
      "Epoch 1/50 - Train Loss: 2.2528, Train Acc: 19.65%, Val Loss: 2.0586, Val Acc: 34.51% (Best: 34.51% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 1.0341, Train Acc: 73.12%, Val Loss: 1.7901, Val Acc: 39.38% (Best: 39.38% @ Epoch 5)\n",
      "Epoch 10/50 - Train Loss: 0.3758, Train Acc: 93.94%, Val Loss: 1.8679, Val Acc: 38.94% (Best: 40.71% @ Epoch 9)\n",
      "Epoch 15/50 - Train Loss: 0.1229, Train Acc: 98.97%, Val Loss: 1.9896, Val Acc: 38.94% (Best: 40.71% @ Epoch 9)\n",
      "Epoch 20/50 - Train Loss: 0.0601, Train Acc: 99.85%, Val Loss: 2.0687, Val Acc: 42.48% (Best: 43.36% @ Epoch 17)\n",
      "Epoch 25/50 - Train Loss: 0.0416, Train Acc: 100.00%, Val Loss: 2.1038, Val Acc: 41.59% (Best: 43.81% @ Epoch 21)\n",
      "Epoch 30/50 - Train Loss: 0.0300, Train Acc: 99.85%, Val Loss: 2.1414, Val Acc: 45.58% (Best: 45.58% @ Epoch 30)\n",
      "Epoch 35/50 - Train Loss: 0.0220, Train Acc: 100.00%, Val Loss: 2.1451, Val Acc: 42.48% (Best: 45.58% @ Epoch 30)\n",
      "Epoch 40/50 - Train Loss: 0.0174, Train Acc: 99.85%, Val Loss: 2.1839, Val Acc: 43.81% (Best: 45.58% @ Epoch 30)\n",
      "Epoch 45/50 - Train Loss: 0.0191, Train Acc: 100.00%, Val Loss: 2.1791, Val Acc: 43.36% (Best: 45.58% @ Epoch 30)\n",
      "Epoch 50/50 - Train Loss: 0.0192, Train Acc: 100.00%, Val Loss: 2.1894, Val Acc: 44.69% (Best: 45.58% @ Epoch 30)\n",
      "Final - Best Val Acc: 45.58% @ Epoch 30\n",
      "\n",
      "✓ DINOv2-Small + 3-Layer (50 epochs):\n",
      "  Best Val Acc: 45.58%\n",
      "  Test Acc: 45.58%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Training: DINOv2-Small + 4-Layer (50 epochs)\n",
      "================================================================================\n",
      "Epoch 1/50 - Train Loss: 2.2990, Train Acc: 16.25%, Val Loss: 2.2029, Val Acc: 25.22% (Best: 25.22% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 1.4437, Train Acc: 56.43%, Val Loss: 1.8712, Val Acc: 35.84% (Best: 35.84% @ Epoch 4)\n",
      "Epoch 10/50 - Train Loss: 0.7295, Train Acc: 83.01%, Val Loss: 1.8448, Val Acc: 38.50% (Best: 38.50% @ Epoch 10)\n",
      "Epoch 15/50 - Train Loss: 0.3458, Train Acc: 93.80%, Val Loss: 1.9789, Val Acc: 36.73% (Best: 38.94% @ Epoch 13)\n",
      "Epoch 20/50 - Train Loss: 0.1705, Train Acc: 98.08%, Val Loss: 2.0849, Val Acc: 37.61% (Best: 41.59% @ Epoch 16)\n",
      "Epoch 25/50 - Train Loss: 0.0969, Train Acc: 99.41%, Val Loss: 2.1266, Val Acc: 40.71% (Best: 41.59% @ Epoch 16)\n",
      "Epoch 30/50 - Train Loss: 0.0800, Train Acc: 99.41%, Val Loss: 2.0954, Val Acc: 40.71% (Best: 41.59% @ Epoch 16)\n",
      "Epoch 35/50 - Train Loss: 0.0608, Train Acc: 99.85%, Val Loss: 2.1508, Val Acc: 41.59% (Best: 41.59% @ Epoch 16)\n",
      "Epoch 40/50 - Train Loss: 0.0582, Train Acc: 99.41%, Val Loss: 2.1922, Val Acc: 40.71% (Best: 41.59% @ Epoch 16)\n",
      "Epoch 45/50 - Train Loss: 0.0513, Train Acc: 99.56%, Val Loss: 2.1809, Val Acc: 41.59% (Best: 41.59% @ Epoch 16)\n",
      "Epoch 50/50 - Train Loss: 0.0508, Train Acc: 99.85%, Val Loss: 2.1856, Val Acc: 41.15% (Best: 41.59% @ Epoch 16)\n",
      "Final - Best Val Acc: 41.59% @ Epoch 16\n",
      "\n",
      "✓ DINOv2-Small + 4-Layer (50 epochs):\n",
      "  Best Val Acc: 41.59%\n",
      "  Test Acc: 42.92%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "Training: DINOv2-Small + 1-Layer (50 epochs)\n",
      "================================================================================\n",
      "Epoch 1/50 - Train Loss: 2.5122, Train Acc: 14.33%, Val Loss: 2.3491, Val Acc: 19.47% (Best: 19.47% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 1.7919, Train Acc: 40.77%, Val Loss: 2.0881, Val Acc: 30.53% (Best: 30.53% @ Epoch 5)\n",
      "Epoch 10/50 - Train Loss: 1.5133, Train Acc: 50.52%, Val Loss: 2.0122, Val Acc: 32.74% (Best: 34.96% @ Epoch 9)\n",
      "Epoch 15/50 - Train Loss: 1.3462, Train Acc: 58.05%, Val Loss: 1.9769, Val Acc: 34.51% (Best: 35.84% @ Epoch 12)\n",
      "Epoch 20/50 - Train Loss: 1.2297, Train Acc: 62.78%, Val Loss: 1.9721, Val Acc: 34.07% (Best: 35.84% @ Epoch 12)\n",
      "Epoch 25/50 - Train Loss: 1.1479, Train Acc: 65.73%, Val Loss: 1.9595, Val Acc: 35.40% (Best: 35.84% @ Epoch 12)\n",
      "Epoch 30/50 - Train Loss: 1.1011, Train Acc: 66.47%, Val Loss: 1.9724, Val Acc: 35.40% (Best: 35.84% @ Epoch 12)\n",
      "Epoch 35/50 - Train Loss: 1.0652, Train Acc: 69.28%, Val Loss: 1.9663, Val Acc: 34.51% (Best: 35.84% @ Epoch 12)\n",
      "Epoch 40/50 - Train Loss: 1.0504, Train Acc: 69.87%, Val Loss: 1.9644, Val Acc: 34.51% (Best: 35.84% @ Epoch 12)\n",
      "Epoch 45/50 - Train Loss: 1.0392, Train Acc: 69.72%, Val Loss: 1.9645, Val Acc: 34.51% (Best: 35.84% @ Epoch 12)\n",
      "Epoch 50/50 - Train Loss: 1.0327, Train Acc: 69.57%, Val Loss: 1.9654, Val Acc: 34.51% (Best: 35.84% @ Epoch 12)\n",
      "Final - Best Val Acc: 35.84% @ Epoch 12\n",
      "\n",
      "✓ DINOv2-Small + 1-Layer (50 epochs):\n",
      "  Best Val Acc: 35.84%\n",
      "  Test Acc: 41.59%\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "EXTENDED TRAINING COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Retrain best configurations with 50 epochs\n",
    "print(\"=\"*80)\n",
    "print(\"RETRAINING BEST CONFIGURATIONS WITH 50 EPOCHS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stage1_extended_results = []\n",
    "epochs_extended = 50\n",
    "\n",
    "# Select top 4 configurations from stage1_results\n",
    "top_configs = sorted(stage1_results, key=lambda x: x['test_acc'], reverse=True)[:4]\n",
    "\n",
    "for config in top_configs:\n",
    "    backbone_name = config['backbone']\n",
    "    classifier_name = config['classifier']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training: {backbone_name} + {classifier_name} (50 epochs)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Get appropriate features\n",
    "    if backbone_name == \"DINOv2-Small\":\n",
    "        train_feat, train_lbl = dinov2_train_features, dinov2_train_labels\n",
    "        val_feat, val_lbl = dinov2_val_features, dinov2_val_labels\n",
    "        test_feat, test_lbl = dinov2_test_features, dinov2_test_labels\n",
    "        feature_dim = dinov2_dim\n",
    "    else:\n",
    "        train_feat, train_lbl = clip_train_features, clip_train_labels\n",
    "        val_feat, val_lbl = clip_val_features, clip_val_labels\n",
    "        test_feat, test_lbl = clip_test_features, clip_test_labels\n",
    "        feature_dim = clip_dim\n",
    "    \n",
    "    # Create fresh classifier\n",
    "    ClassifierClass = dict(classifier_configs)[classifier_name]\n",
    "    if classifier_name == \"1-Layer\":\n",
    "        classifier = ClassifierClass(feature_dim, num_classes=10)\n",
    "    elif classifier_name == \"2-Layer\":\n",
    "        classifier = ClassifierClass(feature_dim, num_classes=10, hidden_dim=512, dropout=0.3)\n",
    "    elif classifier_name == \"3-Layer\":\n",
    "        classifier = ClassifierClass(feature_dim, num_classes=10, hidden_dim1=512, hidden_dim2=256, dropout=0.3)\n",
    "    else:  # 4-Layer\n",
    "        classifier = ClassifierClass(feature_dim, num_classes=10, hidden_dims=[512, 256, 128], dropout=0.3)\n",
    "    \n",
    "    # Train\n",
    "    trained_classifier, best_val_acc, history = train_classifier_on_features(\n",
    "        classifier=classifier,\n",
    "        train_features=train_feat,\n",
    "        train_labels=train_lbl,\n",
    "        val_features=val_feat,\n",
    "        val_labels=val_lbl,\n",
    "        epochs=epochs_extended,\n",
    "        lr=1e-3,\n",
    "        batch_size=64\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    test_acc = evaluate_classifier_on_features(trained_classifier, test_feat, test_lbl, batch_size=64)\n",
    "    \n",
    "    result = {\n",
    "        'backbone': backbone_name,\n",
    "        'classifier': classifier_name,\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'history': history,\n",
    "        'model': trained_classifier\n",
    "    }\n",
    "    stage1_extended_results.append(result)\n",
    "    \n",
    "    print(f\"\\n✓ {backbone_name} + {classifier_name} (50 epochs):\")\n",
    "    print(f\"  Best Val Acc: {best_val_acc:.2f}%\")\n",
    "    print(f\"  Test Acc: {test_acc:.2f}%\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"EXTENDED TRAINING COMPLETE\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2627f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARISON: 20 EPOCHS vs 50 EPOCHS\n",
      "================================================================================\n",
      "\n",
      "          Configuration 20 Epochs Val 20 Epochs Test 50 Epochs Val 50 Epochs Test Improvement\n",
      "DINOv2-Small + 2-Layer        41.59%         44.69%        42.92%         44.69%      +0.00%\n",
      "DINOv2-Small + 3-Layer        42.04%         43.81%        45.58%         45.58%      +1.77%\n",
      "DINOv2-Small + 4-Layer        44.25%         42.92%        41.59%         42.92%      +0.00%\n",
      "DINOv2-Small + 1-Layer        36.28%         35.40%        35.84%         41.59%      +6.19%\n",
      "\n",
      "================================================================================\n",
      "BEST MODEL (50 epochs):\n",
      "  DINOv2-Small + 3-Layer\n",
      "  Val Acc: 45.58%\n",
      "  Test Acc: 45.58%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Compare 20 vs 50 epochs\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: 20 EPOCHS vs 50 EPOCHS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = []\n",
    "for orig in top_configs:\n",
    "    extended = [r for r in stage1_extended_results if r['backbone'] == orig['backbone'] and r['classifier'] == orig['classifier']][0]\n",
    "    comparison_data.append({\n",
    "        'Configuration': f\"{orig['backbone']} + {orig['classifier']}\",\n",
    "        '20 Epochs Val': f\"{orig['best_val_acc']:.2f}%\",\n",
    "        '20 Epochs Test': f\"{orig['test_acc']:.2f}%\",\n",
    "        '50 Epochs Val': f\"{extended['best_val_acc']:.2f}%\",\n",
    "        '50 Epochs Test': f\"{extended['test_acc']:.2f}%\",\n",
    "        'Improvement': f\"{extended['test_acc'] - orig['test_acc']:+.2f}%\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\", comparison_df.to_string(index=False))\n",
    "\n",
    "# Find overall best\n",
    "best_extended = max(stage1_extended_results, key=lambda x: x['test_acc'])\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"BEST MODEL (50 epochs):\")\n",
    "print(f\"  {best_extended['backbone']} + {best_extended['classifier']}\")\n",
    "print(f\"  Val Acc: {best_extended['best_val_acc']:.2f}%\")\n",
    "print(f\"  Test Acc: {best_extended['test_acc']:.2f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0705e2",
   "metadata": {},
   "source": [
    "## 7. Stage 2: Partial Backbone Training with Frozen Classifier\n",
    "\n",
    "Take the best Stage 1 model, freeze its classifier, and train the backbone partially using:\n",
    "- **Strategy A**: Train last N transformer blocks\n",
    "- **Strategy B**: LoRA (Low-Rank Adaptation)\n",
    "- **Strategy C**: Train top + bottom blocks (middle frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a55b67c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Stage 2 training functions\n",
    "def get_trainable_params(model):\n",
    "    \"\"\"Count trainable parameters\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def freeze_all(model):\n",
    "    \"\"\"Freeze all parameters\"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_last_n_blocks(backbone, n_blocks=4):\n",
    "    \"\"\"Unfreeze last N transformer blocks (supports both DINOv2 and CLIP)\"\"\"\n",
    "    freeze_all(backbone)\n",
    "    \n",
    "    # Check model type\n",
    "    if hasattr(backbone, 'blocks'):\n",
    "        # DINOv2 structure: backbone.blocks\n",
    "        total_blocks = len(backbone.blocks)\n",
    "        for i in range(total_blocks - n_blocks, total_blocks):\n",
    "            for param in backbone.blocks[i].parameters():\n",
    "                param.requires_grad = True\n",
    "        print(f\"[DINOv2] Unfroze last {n_blocks} blocks out of {total_blocks}\")\n",
    "    elif hasattr(backbone, 'transformer') and hasattr(backbone.transformer, 'resblocks'):\n",
    "        # CLIP structure: backbone.transformer.resblocks\n",
    "        total_blocks = len(backbone.transformer.resblocks)\n",
    "        for i in range(total_blocks - n_blocks, total_blocks):\n",
    "            for param in backbone.transformer.resblocks[i].parameters():\n",
    "                param.requires_grad = True\n",
    "        print(f\"[CLIP] Unfroze last {n_blocks} blocks out of {total_blocks}\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported backbone architecture\")\n",
    "    \n",
    "    return backbone\n",
    "\n",
    "def unfreeze_top_bottom_blocks(backbone, top_n=2, bottom_n=2):\n",
    "    \"\"\"Unfreeze first N and last N blocks, keep middle frozen (supports both DINOv2 and CLIP)\"\"\"\n",
    "    freeze_all(backbone)\n",
    "    \n",
    "    # Check model type\n",
    "    if hasattr(backbone, 'blocks'):\n",
    "        # DINOv2 structure\n",
    "        total_blocks = len(backbone.blocks)\n",
    "        # Unfreeze first bottom_n blocks\n",
    "        for i in range(bottom_n):\n",
    "            for param in backbone.blocks[i].parameters():\n",
    "                param.requires_grad = True\n",
    "        # Unfreeze last top_n blocks\n",
    "        for i in range(total_blocks - top_n, total_blocks):\n",
    "            for param in backbone.blocks[i].parameters():\n",
    "                param.requires_grad = True\n",
    "        print(f\"[DINOv2] Unfroze first {bottom_n} and last {top_n} blocks (middle {total_blocks - top_n - bottom_n} blocks frozen)\")\n",
    "    elif hasattr(backbone, 'transformer') and hasattr(backbone.transformer, 'resblocks'):\n",
    "        # CLIP structure\n",
    "        total_blocks = len(backbone.transformer.resblocks)\n",
    "        # Unfreeze first bottom_n blocks\n",
    "        for i in range(bottom_n):\n",
    "            for param in backbone.transformer.resblocks[i].parameters():\n",
    "                param.requires_grad = True\n",
    "        # Unfreeze last top_n blocks\n",
    "        for i in range(total_blocks - top_n, total_blocks):\n",
    "            for param in backbone.transformer.resblocks[i].parameters():\n",
    "                param.requires_grad = True\n",
    "        print(f\"[CLIP] Unfroze first {bottom_n} and last {top_n} blocks (middle {total_blocks - top_n - bottom_n} blocks frozen)\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported backbone architecture\")\n",
    "    \n",
    "    return backbone\n",
    "\n",
    "print(\"Stage 2 helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a3da20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 training function defined.\n"
     ]
    }
   ],
   "source": [
    "def train_stage2(backbone, classifier, train_loader, val_loader, test_loader, \n",
    "                 epochs=30, lr=1e-5, strategy_name=\"Stage2\"):\n",
    "    \"\"\"Train backbone with frozen classifier\"\"\"\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    # Freeze classifier\n",
    "    classifier.eval()\n",
    "    for param in classifier.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Move to GPU\n",
    "    backbone = backbone.cuda()\n",
    "    classifier = classifier.cuda()\n",
    "    \n",
    "    # Only optimize backbone parameters\n",
    "    trainable_params = [p for p in backbone.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.AdamW(trainable_params, lr=lr, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_epoch = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    print(f\"Trainable params: {get_trainable_params(backbone):,}\")\n",
    "    print(f\"Training for {epochs} epochs with lr={lr}\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        backbone.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward through backbone + classifier\n",
    "            features = backbone(images)\n",
    "            with torch.no_grad():\n",
    "                outputs = classifier(features)\n",
    "            \n",
    "            # Actually need to compute gradients for classifier output\n",
    "            features = backbone(images)\n",
    "            outputs = classifier(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward (only updates backbone)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(trainable_params, max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Stats\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        \n",
    "        # Validation\n",
    "        backbone.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                features = backbone(images)\n",
    "                outputs = classifier(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Train: {train_acc:.2f}%, Val: {val_acc:.2f}% \"\n",
    "                  f\"(Best: {best_val_acc:.2f}% @ Epoch {best_epoch})\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    backbone.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            features = backbone(images)\n",
    "            outputs = classifier(features)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    test_acc = 100. * test_correct / test_total\n",
    "    \n",
    "    print(f\"\\nFinal - Best Val: {best_val_acc:.2f}%, Test: {test_acc:.2f}%\")\n",
    "    \n",
    "    return backbone, best_val_acc, test_acc, history\n",
    "\n",
    "print(\"Stage 2 training function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2742fc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPARING FOR STAGE 2\n",
      "================================================================================\n",
      "\n",
      "Best Stage 1 model: DINOv2-Small + 3-Layer\n",
      "  Val Acc: 45.58%\n",
      "  Test Acc: 45.58%\n",
      "\n",
      "✓ Prepared for Stage 2:\n",
      "  Backbone: DINOv2-Small\n",
      "  Classifier: 3-Layer (frozen)\n",
      "  Training data: Heavy augmentation enabled\n",
      "  Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "# Prepare for Stage 2: Get best model and recreate dataloaders with heavy augmentation\n",
    "print(\"=\"*80)\n",
    "print(\"PREPARING FOR STAGE 2\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get best extended model\n",
    "best_model = max(stage1_extended_results, key=lambda x: x['test_acc'])\n",
    "print(f\"\\nBest Stage 1 model: {best_model['backbone']} + {best_model['classifier']}\")\n",
    "print(f\"  Val Acc: {best_model['best_val_acc']:.2f}%\")\n",
    "print(f\"  Test Acc: {best_model['test_acc']:.2f}%\")\n",
    "\n",
    "# We'll use DINOv2 for Stage 2 (better performance)\n",
    "best_backbone = dinov2_small\n",
    "best_classifier = best_model['model']\n",
    "\n",
    "# Create dataloaders with heavy augmentation for Stage 2\n",
    "train_dataset_heavy = BoneFractureDataset(train_paths, train_labels, transform=heavy_transform)\n",
    "train_loader_heavy = DataLoader(train_dataset_heavy, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "print(f\"\\n✓ Prepared for Stage 2:\")\n",
    "print(f\"  Backbone: DINOv2-Small\")\n",
    "print(f\"  Classifier: {best_model['classifier']} (frozen)\")\n",
    "print(f\"  Training data: Heavy augmentation enabled\")\n",
    "print(f\"  Batch size: 32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae78a2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STAGE 2: PARTIAL BACKBONE TRAINING\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "STRATEGY A: Train Last 4 Transformer Blocks\n",
      "================================================================================\n",
      "Unfroze last 4 blocks out of 12\n",
      "Trainable params: 7,100,928\n",
      "Training for 30 epochs with lr=5e-06\n",
      "\n",
      "Epoch 1/30 - Train: 76.51%, Val: 40.27% (Best: 40.27% @ Epoch 1)\n",
      "Epoch 10/30 - Train: 92.02%, Val: 47.79% (Best: 47.79% @ Epoch 10)\n",
      "Epoch 20/30 - Train: 96.75%, Val: 49.56% (Best: 51.33% @ Epoch 19)\n",
      "Epoch 30/30 - Train: 97.64%, Val: 50.88% (Best: 51.77% @ Epoch 25)\n",
      "\n",
      "Final - Best Val: 51.77%, Test: 51.77%\n",
      "\n",
      "✓ Strategy A Complete - Test Acc: 51.77%\n",
      "\n",
      "================================================================================\n",
      "STRATEGY B: Train Last 6 Transformer Blocks\n",
      "================================================================================\n",
      "Unfroze last 6 blocks out of 12\n",
      "Trainable params: 10,651,392\n",
      "Training for 30 epochs with lr=5e-06\n",
      "\n",
      "Epoch 1/30 - Train: 72.82%, Val: 45.58% (Best: 45.58% @ Epoch 1)\n",
      "Epoch 10/30 - Train: 95.72%, Val: 50.44% (Best: 50.44% @ Epoch 10)\n",
      "Epoch 20/30 - Train: 98.23%, Val: 47.79% (Best: 50.44% @ Epoch 10)\n",
      "Epoch 30/30 - Train: 98.82%, Val: 49.56% (Best: 50.88% @ Epoch 26)\n",
      "\n",
      "Final - Best Val: 50.88%, Test: 54.42%\n",
      "\n",
      "✓ Strategy B Complete - Test Acc: 54.42%\n",
      "\n",
      "================================================================================\n",
      "STRATEGY C: Train Top 2 + Bottom 2 Blocks (Middle Frozen)\n",
      "================================================================================\n",
      "Unfroze first 2 and last 2 blocks (middle 8 blocks frozen)\n",
      "Trainable params: 7,100,928\n",
      "Training for 30 epochs with lr=5e-06\n",
      "\n",
      "Epoch 1/30 - Train: 78.29%, Val: 44.25% (Best: 44.25% @ Epoch 1)\n",
      "Epoch 10/30 - Train: 89.07%, Val: 44.25% (Best: 46.46% @ Epoch 8)\n",
      "Epoch 20/30 - Train: 95.13%, Val: 46.90% (Best: 48.67% @ Epoch 17)\n",
      "Epoch 30/30 - Train: 95.27%, Val: 49.12% (Best: 49.56% @ Epoch 23)\n",
      "\n",
      "Final - Best Val: 49.56%, Test: 51.33%\n",
      "\n",
      "✓ Strategy C Complete - Test Acc: 51.33%\n",
      "\n",
      "================================================================================\n",
      "STAGE 2 COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Stage 2: Train with different partial training strategies\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 2: PARTIAL BACKBONE TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stage2_results = []\n",
    "\n",
    "# Strategy A: Train last 4 blocks\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STRATEGY A: Train Last 4 Transformer Blocks\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "import copy\n",
    "backbone_strategy_a = copy.deepcopy(best_backbone)\n",
    "classifier_strategy_a = copy.deepcopy(best_classifier)\n",
    "\n",
    "backbone_strategy_a = unfreeze_last_n_blocks(backbone_strategy_a, n_blocks=4)\n",
    "\n",
    "trained_backbone_a, val_acc_a, test_acc_a, history_a = train_stage2(\n",
    "    backbone=backbone_strategy_a,\n",
    "    classifier=classifier_strategy_a,\n",
    "    train_loader=train_loader_heavy,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30,\n",
    "    lr=5e-6,\n",
    "    strategy_name=\"Strategy A\"\n",
    ")\n",
    "\n",
    "stage2_results.append({\n",
    "    'strategy': 'Last 4 Blocks',\n",
    "    'val_acc': val_acc_a,\n",
    "    'test_acc': test_acc_a,\n",
    "    'history': history_a,\n",
    "    'backbone': trained_backbone_a,\n",
    "    'classifier': classifier_strategy_a\n",
    "})\n",
    "\n",
    "print(f\"\\n✓ Strategy A Complete - Test Acc: {test_acc_a:.2f}%\")\n",
    "\n",
    "\n",
    "# Strategy B: Train last 6 blocks (more aggressive)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STRATEGY B: Train Last 6 Transformer Blocks\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "backbone_strategy_b = copy.deepcopy(best_backbone)\n",
    "classifier_strategy_b = copy.deepcopy(best_classifier)\n",
    "\n",
    "backbone_strategy_b = unfreeze_last_n_blocks(backbone_strategy_b, n_blocks=6)\n",
    "\n",
    "trained_backbone_b, val_acc_b, test_acc_b, history_b = train_stage2(\n",
    "    backbone=backbone_strategy_b,\n",
    "    classifier=classifier_strategy_b,\n",
    "    train_loader=train_loader_heavy,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30,\n",
    "    lr=5e-6,\n",
    "    strategy_name=\"Strategy B\"\n",
    ")\n",
    "\n",
    "stage2_results.append({\n",
    "    'strategy': 'Last 6 Blocks',\n",
    "    'val_acc': val_acc_b,\n",
    "    'test_acc': test_acc_b,\n",
    "    'history': history_b,\n",
    "    'backbone': trained_backbone_b,\n",
    "    'classifier': classifier_strategy_b\n",
    "})\n",
    "\n",
    "print(f\"\\n✓ Strategy B Complete - Test Acc: {test_acc_b:.2f}%\")\n",
    "\n",
    "\n",
    "# Strategy C: Train top 2 + bottom 2 blocks\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STRATEGY C: Train Top 2 + Bottom 2 Blocks (Middle Frozen)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "backbone_strategy_c = copy.deepcopy(best_backbone)\n",
    "classifier_strategy_c = copy.deepcopy(best_classifier)\n",
    "\n",
    "backbone_strategy_c = unfreeze_top_bottom_blocks(backbone_strategy_c, top_n=2, bottom_n=2)\n",
    "\n",
    "trained_backbone_c, val_acc_c, test_acc_c, history_c = train_stage2(\n",
    "    backbone=backbone_strategy_c,\n",
    "    classifier=classifier_strategy_c,\n",
    "    train_loader=train_loader_heavy,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30,\n",
    "    lr=5e-6,\n",
    "    strategy_name=\"Strategy C\"\n",
    ")\n",
    "\n",
    "stage2_results.append({\n",
    "    'strategy': 'Top 2 + Bottom 2 Blocks',\n",
    "    'val_acc': val_acc_c,\n",
    "    'test_acc': test_acc_c,\n",
    "    'history': history_c,\n",
    "    'backbone': trained_backbone_c,\n",
    "    'classifier': classifier_strategy_c\n",
    "})\n",
    "\n",
    "print(f\"\\n✓ Strategy C Complete - Test Acc: {test_acc_c:.2f}%\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STAGE 2 COMPLETE\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2 Results Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 2 RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stage2_df = pd.DataFrame([\n",
    "    {\n",
    "        'Strategy': r['strategy'],\n",
    "        'Best Val Acc (%)': f\"{r['val_acc']:.2f}\",\n",
    "        'Test Acc (%)': f\"{r['test_acc']:.2f}\"\n",
    "    }\n",
    "    for r in stage2_results\n",
    "])\n",
    "\n",
    "print(\"\\n\", stage2_df.to_string(index=False))\n",
    "\n",
    "# Compare with Stage 1 best\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COMPARISON WITH STAGE 1\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Stage 1 Best (50 epochs): {best_model['test_acc']:.2f}%\")\n",
    "print(f\"\\nStage 2 Results:\")\n",
    "for r in stage2_results:\n",
    "    improvement = r['test_acc'] - best_model['test_acc']\n",
    "    print(f\"  {r['strategy']}: {r['test_acc']:.2f}% ({improvement:+.2f}%)\")\n",
    "\n",
    "best_stage2 = max(stage2_results, key=lambda x: x['test_acc'])\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"BEST STAGE 2 MODEL:\")\n",
    "print(f\"  Strategy: {best_stage2['strategy']}\")\n",
    "print(f\"  Val Acc: {best_stage2['val_acc']:.2f}%\")\n",
    "print(f\"  Test Acc: {best_stage2['test_acc']:.2f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b43c8a",
   "metadata": {},
   "source": [
    "## Stage 2B: CLIP Partial Backbone Training\n",
    "\n",
    "Apply the same partial training strategies to the best CLIP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81c5ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BEST CLIP MODEL FROM STAGE 1\n",
      "================================================================================\n",
      "Configuration: CLIP-Base + 2-Layer\n",
      "Val Acc: 34.96%\n",
      "Test Acc: 34.51%\n",
      "================================================================================\n",
      "\n",
      "✓ CLIP model prepared for Stage 2 training\n"
     ]
    }
   ],
   "source": [
    "# Get best CLIP model from extended training (or original if not extended)\n",
    "clip_extended = [r for r in stage1_extended_results if r['backbone'] == 'CLIP-Base']\n",
    "if clip_extended:\n",
    "    best_clip_model = max(clip_extended, key=lambda x: x['test_acc'])\n",
    "else:\n",
    "    # Use original stage1 results\n",
    "    best_clip_model = max([r for r in stage1_results if r['backbone'] == 'CLIP-Base'], \n",
    "                          key=lambda x: x['test_acc'])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BEST CLIP MODEL FROM STAGE 1\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Configuration: CLIP-Base + {best_clip_model['classifier']}\")\n",
    "print(f\"Val Acc: {best_clip_model['best_val_acc']:.2f}%\")\n",
    "print(f\"Test Acc: {best_clip_model['test_acc']:.2f}%\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare CLIP backbone and classifier\n",
    "best_clip_backbone = clip_visual\n",
    "best_clip_classifier = best_clip_model['model']\n",
    "\n",
    "print(\"\\n✓ CLIP model prepared for Stage 2 training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9123201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STAGE 2B: CLIP PARTIAL BACKBONE TRAINING\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CLIP STRATEGY A: Train Last 4 Transformer Blocks\n",
      "================================================================================\n",
      "[CLIP] Unfroze last 4 blocks out of 12\n",
      "Trainable params: 28,351,488\n",
      "Training for 30 epochs with lr=5e-06\n",
      "\n",
      "Epoch 1/30 - Train: 50.66%, Val: 38.50% (Best: 38.50% @ Epoch 1)\n",
      "Epoch 10/30 - Train: 79.62%, Val: 43.36% (Best: 47.79% @ Epoch 7)\n",
      "Epoch 20/30 - Train: 90.25%, Val: 50.44% (Best: 50.44% @ Epoch 20)\n",
      "Epoch 30/30 - Train: 90.69%, Val: 46.90% (Best: 50.44% @ Epoch 20)\n",
      "\n",
      "Final - Best Val: 50.44%, Test: 42.04%\n",
      "\n",
      "✓ CLIP Strategy A Complete - Test Acc: 42.04%\n",
      "\n",
      "================================================================================\n",
      "CLIP STRATEGY B: Train Last 6 Transformer Blocks\n",
      "================================================================================\n",
      "[CLIP] Unfroze last 6 blocks out of 12\n",
      "Trainable params: 42,527,232\n",
      "Training for 30 epochs with lr=5e-06\n",
      "\n",
      "Epoch 1/30 - Train: 48.15%, Val: 37.61% (Best: 37.61% @ Epoch 1)\n",
      "Epoch 10/30 - Train: 89.51%, Val: 50.00% (Best: 50.00% @ Epoch 10)\n",
      "Epoch 20/30 - Train: 98.38%, Val: 51.33% (Best: 51.77% @ Epoch 13)\n"
     ]
    }
   ],
   "source": [
    "# Stage 2B: Train CLIP with different partial training strategies\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 2B: CLIP PARTIAL BACKBONE TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stage2_clip_results = []\n",
    "\n",
    "# CLIP Strategy A: Train last 4 blocks\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CLIP STRATEGY A: Train Last 4 Transformer Blocks\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "import copy\n",
    "clip_backbone_strategy_a = copy.deepcopy(best_clip_backbone)\n",
    "clip_classifier_strategy_a = copy.deepcopy(best_clip_classifier)\n",
    "\n",
    "clip_backbone_strategy_a = unfreeze_last_n_blocks(clip_backbone_strategy_a, n_blocks=4)\n",
    "\n",
    "trained_clip_backbone_a, clip_val_acc_a, clip_test_acc_a, clip_history_a = train_stage2(\n",
    "    backbone=clip_backbone_strategy_a,\n",
    "    classifier=clip_classifier_strategy_a,\n",
    "    train_loader=train_loader_heavy,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30,\n",
    "    lr=5e-6,\n",
    "    strategy_name=\"CLIP Strategy A\"\n",
    ")\n",
    "\n",
    "stage2_clip_results.append({\n",
    "    'strategy': 'Last 4 Blocks',\n",
    "    'val_acc': clip_val_acc_a,\n",
    "    'test_acc': clip_test_acc_a,\n",
    "    'history': clip_history_a,\n",
    "    'backbone': trained_clip_backbone_a,\n",
    "    'classifier': clip_classifier_strategy_a\n",
    "})\n",
    "\n",
    "print(f\"\\n✓ CLIP Strategy A Complete - Test Acc: {clip_test_acc_a:.2f}%\")\n",
    "\n",
    "\n",
    "# CLIP Strategy B: Train last 6 blocks (more aggressive)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CLIP STRATEGY B: Train Last 6 Transformer Blocks\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "clip_backbone_strategy_b = copy.deepcopy(best_clip_backbone)\n",
    "clip_classifier_strategy_b = copy.deepcopy(best_clip_classifier)\n",
    "\n",
    "clip_backbone_strategy_b = unfreeze_last_n_blocks(clip_backbone_strategy_b, n_blocks=6)\n",
    "\n",
    "trained_clip_backbone_b, clip_val_acc_b, clip_test_acc_b, clip_history_b = train_stage2(\n",
    "    backbone=clip_backbone_strategy_b,\n",
    "    classifier=clip_classifier_strategy_b,\n",
    "    train_loader=train_loader_heavy,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30,\n",
    "    lr=5e-6,\n",
    "    strategy_name=\"CLIP Strategy B\"\n",
    ")\n",
    "\n",
    "stage2_clip_results.append({\n",
    "    'strategy': 'Last 6 Blocks',\n",
    "    'val_acc': clip_val_acc_b,\n",
    "    'test_acc': clip_test_acc_b,\n",
    "    'history': clip_history_b,\n",
    "    'backbone': trained_clip_backbone_b,\n",
    "    'classifier': clip_classifier_strategy_b\n",
    "})\n",
    "\n",
    "print(f\"\\n✓ CLIP Strategy B Complete - Test Acc: {clip_test_acc_b:.2f}%\")\n",
    "\n",
    "\n",
    "# CLIP Strategy C: Train top 2 + bottom 2 blocks\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CLIP STRATEGY C: Train Top 2 + Bottom 2 Blocks (Middle Frozen)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "clip_backbone_strategy_c = copy.deepcopy(best_clip_backbone)\n",
    "clip_classifier_strategy_c = copy.deepcopy(best_clip_classifier)\n",
    "\n",
    "clip_backbone_strategy_c = unfreeze_top_bottom_blocks(clip_backbone_strategy_c, top_n=2, bottom_n=2)\n",
    "\n",
    "trained_clip_backbone_c, clip_val_acc_c, clip_test_acc_c, clip_history_c = train_stage2(\n",
    "    backbone=clip_backbone_strategy_c,\n",
    "    classifier=clip_classifier_strategy_c,\n",
    "    train_loader=train_loader_heavy,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=30,\n",
    "    lr=5e-6,\n",
    "    strategy_name=\"CLIP Strategy C\"\n",
    ")\n",
    "\n",
    "stage2_clip_results.append({\n",
    "    'strategy': 'Top 2 + Bottom 2 Blocks',\n",
    "    'val_acc': clip_val_acc_c,\n",
    "    'test_acc': clip_test_acc_c,\n",
    "    'history': clip_history_c,\n",
    "    'backbone': trained_clip_backbone_c,\n",
    "    'classifier': clip_classifier_strategy_c\n",
    "})\n",
    "\n",
    "print(f\"\\n✓ CLIP Strategy C Complete - Test Acc: {clip_test_acc_c:.2f}%\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"STAGE 2B COMPLETE (CLIP)\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77588f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2B CLIP Results Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 2B CLIP RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stage2_clip_df = pd.DataFrame([\n",
    "    {\n",
    "        'Strategy': r['strategy'],\n",
    "        'Best Val Acc (%)': f\"{r['val_acc']:.2f}\",\n",
    "        'Test Acc (%)': f\"{r['test_acc']:.2f}\"\n",
    "    }\n",
    "    for r in stage2_clip_results\n",
    "])\n",
    "\n",
    "print(\"\\n\", stage2_clip_df.to_string(index=False))\n",
    "\n",
    "# Compare with Stage 1 best CLIP\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COMPARISON WITH STAGE 1 CLIP\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Stage 1 Best CLIP (50 epochs): {best_clip_model['test_acc']:.2f}%\")\n",
    "print(f\"\\nStage 2B CLIP Results:\")\n",
    "for r in stage2_clip_results:\n",
    "    improvement = r['test_acc'] - best_clip_model['test_acc']\n",
    "    print(f\"  {r['strategy']}: {r['test_acc']:.2f}% ({improvement:+.2f}%)\")\n",
    "\n",
    "best_stage2_clip = max(stage2_clip_results, key=lambda x: x['test_acc'])\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"BEST STAGE 2B CLIP MODEL:\")\n",
    "print(f\"  Strategy: {best_stage2_clip['strategy']}\")\n",
    "print(f\"  Val Acc: {best_stage2_clip['val_acc']:.2f}%\")\n",
    "print(f\"  Test Acc: {best_stage2_clip['test_acc']:.2f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Stage 2 Results: DINOv2 vs CLIP\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 2 COMPLETE: DINOv2 vs CLIP COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "combined_stage2 = []\n",
    "\n",
    "# DINOv2 results\n",
    "for r in stage2_results:\n",
    "    combined_stage2.append({\n",
    "        'Backbone': 'DINOv2-Small',\n",
    "        'Strategy': r['strategy'],\n",
    "        'Val Acc (%)': f\"{r['val_acc']:.2f}\",\n",
    "        'Test Acc (%)': f\"{r['test_acc']:.2f}\"\n",
    "    })\n",
    "\n",
    "# CLIP results\n",
    "for r in stage2_clip_results:\n",
    "    combined_stage2.append({\n",
    "        'Backbone': 'CLIP-Base',\n",
    "        'Strategy': r['strategy'],\n",
    "        'Val Acc (%)': f\"{r['val_acc']:.2f}\",\n",
    "        'Test Acc (%)': f\"{r['test_acc']:.2f}\"\n",
    "    })\n",
    "\n",
    "combined_df = pd.DataFrame(combined_stage2)\n",
    "print(\"\\n\", combined_df.to_string(index=False))\n",
    "\n",
    "# Overall best\n",
    "all_stage2_results = stage2_results + stage2_clip_results\n",
    "overall_best = max(all_stage2_results, key=lambda x: x['test_acc'])\n",
    "best_backbone_name = 'DINOv2-Small' if overall_best in stage2_results else 'CLIP-Base'\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"OVERALL BEST STAGE 2 MODEL:\")\n",
    "print(f\"  Backbone: {best_backbone_name}\")\n",
    "print(f\"  Strategy: {overall_best['strategy']}\")\n",
    "print(f\"  Val Acc: {overall_best['val_acc']:.2f}%\")\n",
    "print(f\"  Test Acc: {overall_best['test_acc']:.2f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f95ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "RETRAINING CLIP CLASSIFIERS WITH HIGHER EPOCHS (50)\n",
      "################################################################################\n",
      "\n",
      "\n",
      "--- CLIP: Testing 1-Layer Classifier ---\n",
      "Epoch 1/50 - Train Loss: 2.2742, Train Acc: 14.62%, Val Loss: 2.2416, Val Acc: 17.26% (Best: 17.26% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 2.0766, Train Acc: 27.62%, Val Loss: 2.1381, Val Acc: 22.12% (Best: 23.45% @ Epoch 4)\n",
      "Epoch 10/50 - Train Loss: 1.9603, Train Acc: 33.97%, Val Loss: 2.0846, Val Acc: 25.22% (Best: 27.43% @ Epoch 9)\n",
      "Epoch 15/50 - Train Loss: 1.8888, Train Acc: 34.56%, Val Loss: 2.0515, Val Acc: 28.32% (Best: 29.65% @ Epoch 12)\n",
      "Epoch 10/50 - Train Loss: 1.9603, Train Acc: 33.97%, Val Loss: 2.0846, Val Acc: 25.22% (Best: 27.43% @ Epoch 9)\n",
      "Epoch 15/50 - Train Loss: 1.8888, Train Acc: 34.56%, Val Loss: 2.0515, Val Acc: 28.32% (Best: 29.65% @ Epoch 12)\n",
      "Epoch 20/50 - Train Loss: 1.8236, Train Acc: 39.14%, Val Loss: 2.0392, Val Acc: 30.09% (Best: 30.97% @ Epoch 19)\n",
      "Epoch 25/50 - Train Loss: 1.7886, Train Acc: 39.73%, Val Loss: 2.0335, Val Acc: 29.20% (Best: 30.97% @ Epoch 19)\n",
      "Epoch 20/50 - Train Loss: 1.8236, Train Acc: 39.14%, Val Loss: 2.0392, Val Acc: 30.09% (Best: 30.97% @ Epoch 19)\n",
      "Epoch 25/50 - Train Loss: 1.7886, Train Acc: 39.73%, Val Loss: 2.0335, Val Acc: 29.20% (Best: 30.97% @ Epoch 19)\n",
      "Epoch 30/50 - Train Loss: 1.7652, Train Acc: 41.80%, Val Loss: 2.0223, Val Acc: 30.53% (Best: 30.97% @ Epoch 19)\n",
      "Epoch 35/50 - Train Loss: 1.7484, Train Acc: 42.39%, Val Loss: 2.0220, Val Acc: 30.97% (Best: 31.42% @ Epoch 32)\n",
      "Epoch 30/50 - Train Loss: 1.7652, Train Acc: 41.80%, Val Loss: 2.0223, Val Acc: 30.53% (Best: 30.97% @ Epoch 19)\n",
      "Epoch 35/50 - Train Loss: 1.7484, Train Acc: 42.39%, Val Loss: 2.0220, Val Acc: 30.97% (Best: 31.42% @ Epoch 32)\n",
      "Epoch 40/50 - Train Loss: 1.7390, Train Acc: 43.13%, Val Loss: 2.0216, Val Acc: 30.09% (Best: 31.42% @ Epoch 32)\n",
      "Epoch 45/50 - Train Loss: 1.7282, Train Acc: 43.43%, Val Loss: 2.0210, Val Acc: 30.53% (Best: 31.42% @ Epoch 32)\n",
      "Epoch 50/50 - Train Loss: 1.7381, Train Acc: 43.13%, Val Loss: 2.0209, Val Acc: 30.97% (Best: 31.42% @ Epoch 32)\n",
      "Final - Best Val Acc: 31.42% @ Epoch 32\n",
      "Epoch 40/50 - Train Loss: 1.7390, Train Acc: 43.13%, Val Loss: 2.0216, Val Acc: 30.09% (Best: 31.42% @ Epoch 32)\n",
      "Epoch 45/50 - Train Loss: 1.7282, Train Acc: 43.43%, Val Loss: 2.0210, Val Acc: 30.53% (Best: 31.42% @ Epoch 32)\n",
      "Epoch 50/50 - Train Loss: 1.7381, Train Acc: 43.13%, Val Loss: 2.0209, Val Acc: 30.97% (Best: 31.42% @ Epoch 32)\n",
      "Final - Best Val Acc: 31.42% @ Epoch 32\n",
      "\n",
      "✓ CLIP + 1-Layer: Best Val 31.42%, Test 26.99%\n",
      "\n",
      "--- CLIP: Testing 2-Layer Classifier ---\n",
      "Epoch 1/50 - Train Loss: 2.1856, Train Acc: 20.38%, Val Loss: 2.1830, Val Acc: 26.11% (Best: 26.11% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 1.1120, Train Acc: 67.95%, Val Loss: 1.9681, Val Acc: 33.19% (Best: 33.19% @ Epoch 5)\n",
      "\n",
      "✓ CLIP + 1-Layer: Best Val 31.42%, Test 26.99%\n",
      "\n",
      "--- CLIP: Testing 2-Layer Classifier ---\n",
      "Epoch 1/50 - Train Loss: 2.1856, Train Acc: 20.38%, Val Loss: 2.1830, Val Acc: 26.11% (Best: 26.11% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 1.1120, Train Acc: 67.95%, Val Loss: 1.9681, Val Acc: 33.19% (Best: 33.19% @ Epoch 5)\n",
      "Epoch 10/50 - Train Loss: 0.5049, Train Acc: 93.50%, Val Loss: 2.1905, Val Acc: 34.96% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 15/50 - Train Loss: 0.2119, Train Acc: 99.26%, Val Loss: 2.3764, Val Acc: 35.40% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 10/50 - Train Loss: 0.5049, Train Acc: 93.50%, Val Loss: 2.1905, Val Acc: 34.96% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 15/50 - Train Loss: 0.2119, Train Acc: 99.26%, Val Loss: 2.3764, Val Acc: 35.40% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 20/50 - Train Loss: 0.1094, Train Acc: 100.00%, Val Loss: 2.5387, Val Acc: 33.19% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 25/50 - Train Loss: 0.0672, Train Acc: 99.85%, Val Loss: 2.6167, Val Acc: 35.84% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 20/50 - Train Loss: 0.1094, Train Acc: 100.00%, Val Loss: 2.5387, Val Acc: 33.19% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 25/50 - Train Loss: 0.0672, Train Acc: 99.85%, Val Loss: 2.6167, Val Acc: 35.84% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 30/50 - Train Loss: 0.0426, Train Acc: 100.00%, Val Loss: 2.7150, Val Acc: 37.17% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 35/50 - Train Loss: 0.0377, Train Acc: 100.00%, Val Loss: 2.7656, Val Acc: 35.84% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 30/50 - Train Loss: 0.0426, Train Acc: 100.00%, Val Loss: 2.7150, Val Acc: 37.17% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 35/50 - Train Loss: 0.0377, Train Acc: 100.00%, Val Loss: 2.7656, Val Acc: 35.84% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 40/50 - Train Loss: 0.0349, Train Acc: 100.00%, Val Loss: 2.7442, Val Acc: 35.40% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 45/50 - Train Loss: 0.0309, Train Acc: 100.00%, Val Loss: 2.7728, Val Acc: 35.40% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 40/50 - Train Loss: 0.0349, Train Acc: 100.00%, Val Loss: 2.7442, Val Acc: 35.40% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 45/50 - Train Loss: 0.0309, Train Acc: 100.00%, Val Loss: 2.7728, Val Acc: 35.40% (Best: 38.05% @ Epoch 7)\n",
      "Epoch 50/50 - Train Loss: 0.0298, Train Acc: 100.00%, Val Loss: 2.7727, Val Acc: 35.84% (Best: 38.05% @ Epoch 7)\n",
      "Final - Best Val Acc: 38.05% @ Epoch 7\n",
      "\n",
      "✓ CLIP + 2-Layer: Best Val 38.05%, Test 33.19%\n",
      "\n",
      "--- CLIP: Testing 3-Layer Classifier ---\n",
      "Epoch 1/50 - Train Loss: 2.2445, Train Acc: 19.05%, Val Loss: 2.2421, Val Acc: 25.66% (Best: 25.66% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 1.2611, Train Acc: 61.89%, Val Loss: 1.9523, Val Acc: 34.96% (Best: 34.96% @ Epoch 5)\n",
      "Epoch 50/50 - Train Loss: 0.0298, Train Acc: 100.00%, Val Loss: 2.7727, Val Acc: 35.84% (Best: 38.05% @ Epoch 7)\n",
      "Final - Best Val Acc: 38.05% @ Epoch 7\n",
      "\n",
      "✓ CLIP + 2-Layer: Best Val 38.05%, Test 33.19%\n",
      "\n",
      "--- CLIP: Testing 3-Layer Classifier ---\n",
      "Epoch 1/50 - Train Loss: 2.2445, Train Acc: 19.05%, Val Loss: 2.2421, Val Acc: 25.66% (Best: 25.66% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 1.2611, Train Acc: 61.89%, Val Loss: 1.9523, Val Acc: 34.96% (Best: 34.96% @ Epoch 5)\n",
      "Epoch 10/50 - Train Loss: 0.6170, Train Acc: 86.56%, Val Loss: 2.0679, Val Acc: 32.30% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 15/50 - Train Loss: 0.2401, Train Acc: 96.75%, Val Loss: 2.2656, Val Acc: 34.07% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 10/50 - Train Loss: 0.6170, Train Acc: 86.56%, Val Loss: 2.0679, Val Acc: 32.30% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 15/50 - Train Loss: 0.2401, Train Acc: 96.75%, Val Loss: 2.2656, Val Acc: 34.07% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 20/50 - Train Loss: 0.1379, Train Acc: 98.52%, Val Loss: 2.5157, Val Acc: 33.19% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 25/50 - Train Loss: 0.0721, Train Acc: 99.26%, Val Loss: 2.5734, Val Acc: 34.96% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 20/50 - Train Loss: 0.1379, Train Acc: 98.52%, Val Loss: 2.5157, Val Acc: 33.19% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 25/50 - Train Loss: 0.0721, Train Acc: 99.26%, Val Loss: 2.5734, Val Acc: 34.96% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 30/50 - Train Loss: 0.0470, Train Acc: 99.70%, Val Loss: 2.6221, Val Acc: 35.40% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 35/50 - Train Loss: 0.0368, Train Acc: 99.85%, Val Loss: 2.5862, Val Acc: 33.63% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 30/50 - Train Loss: 0.0470, Train Acc: 99.70%, Val Loss: 2.6221, Val Acc: 35.40% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 35/50 - Train Loss: 0.0368, Train Acc: 99.85%, Val Loss: 2.5862, Val Acc: 33.63% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 40/50 - Train Loss: 0.0333, Train Acc: 99.70%, Val Loss: 2.6268, Val Acc: 34.51% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 45/50 - Train Loss: 0.0277, Train Acc: 100.00%, Val Loss: 2.6238, Val Acc: 34.07% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 40/50 - Train Loss: 0.0333, Train Acc: 99.70%, Val Loss: 2.6268, Val Acc: 34.51% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 45/50 - Train Loss: 0.0277, Train Acc: 100.00%, Val Loss: 2.6238, Val Acc: 34.07% (Best: 36.28% @ Epoch 6)\n",
      "Epoch 50/50 - Train Loss: 0.0251, Train Acc: 100.00%, Val Loss: 2.6253, Val Acc: 34.07% (Best: 36.28% @ Epoch 6)\n",
      "Final - Best Val Acc: 36.28% @ Epoch 6\n",
      "\n",
      "✓ CLIP + 3-Layer: Best Val 36.28%, Test 30.97%\n",
      "\n",
      "--- CLIP: Testing 4-Layer Classifier ---\n",
      "Epoch 1/50 - Train Loss: 2.2554, Train Acc: 18.17%, Val Loss: 2.2577, Val Acc: 25.22% (Best: 25.22% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 1.5712, Train Acc: 47.42%, Val Loss: 1.9769, Val Acc: 30.53% (Best: 30.53% @ Epoch 5)\n",
      "Epoch 50/50 - Train Loss: 0.0251, Train Acc: 100.00%, Val Loss: 2.6253, Val Acc: 34.07% (Best: 36.28% @ Epoch 6)\n",
      "Final - Best Val Acc: 36.28% @ Epoch 6\n",
      "\n",
      "✓ CLIP + 3-Layer: Best Val 36.28%, Test 30.97%\n",
      "\n",
      "--- CLIP: Testing 4-Layer Classifier ---\n",
      "Epoch 1/50 - Train Loss: 2.2554, Train Acc: 18.17%, Val Loss: 2.2577, Val Acc: 25.22% (Best: 25.22% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 1.5712, Train Acc: 47.42%, Val Loss: 1.9769, Val Acc: 30.53% (Best: 30.53% @ Epoch 5)\n",
      "Epoch 10/50 - Train Loss: 0.9897, Train Acc: 72.53%, Val Loss: 1.9977, Val Acc: 36.73% (Best: 36.73% @ Epoch 10)\n",
      "Epoch 15/50 - Train Loss: 0.5299, Train Acc: 87.44%, Val Loss: 2.1061, Val Acc: 31.86% (Best: 36.73% @ Epoch 10)\n",
      "Epoch 10/50 - Train Loss: 0.9897, Train Acc: 72.53%, Val Loss: 1.9977, Val Acc: 36.73% (Best: 36.73% @ Epoch 10)\n",
      "Epoch 15/50 - Train Loss: 0.5299, Train Acc: 87.44%, Val Loss: 2.1061, Val Acc: 31.86% (Best: 36.73% @ Epoch 10)\n",
      "Epoch 20/50 - Train Loss: 0.3282, Train Acc: 92.32%, Val Loss: 2.2032, Val Acc: 33.19% (Best: 36.73% @ Epoch 10)\n",
      "Epoch 25/50 - Train Loss: 0.1936, Train Acc: 96.90%, Val Loss: 2.4428, Val Acc: 32.74% (Best: 36.73% @ Epoch 10)\n",
      "Epoch 20/50 - Train Loss: 0.3282, Train Acc: 92.32%, Val Loss: 2.2032, Val Acc: 33.19% (Best: 36.73% @ Epoch 10)\n",
      "Epoch 25/50 - Train Loss: 0.1936, Train Acc: 96.90%, Val Loss: 2.4428, Val Acc: 32.74% (Best: 36.73% @ Epoch 10)\n",
      "Epoch 30/50 - Train Loss: 0.1486, Train Acc: 96.75%, Val Loss: 2.3788, Val Acc: 35.40% (Best: 36.73% @ Epoch 10)\n",
      "Epoch 35/50 - Train Loss: 0.0942, Train Acc: 98.67%, Val Loss: 2.4345, Val Acc: 36.28% (Best: 38.05% @ Epoch 31)\n",
      "Epoch 30/50 - Train Loss: 0.1486, Train Acc: 96.75%, Val Loss: 2.3788, Val Acc: 35.40% (Best: 36.73% @ Epoch 10)\n",
      "Epoch 35/50 - Train Loss: 0.0942, Train Acc: 98.67%, Val Loss: 2.4345, Val Acc: 36.28% (Best: 38.05% @ Epoch 31)\n",
      "Epoch 40/50 - Train Loss: 0.0822, Train Acc: 98.82%, Val Loss: 2.4785, Val Acc: 36.73% (Best: 38.05% @ Epoch 31)\n",
      "Epoch 45/50 - Train Loss: 0.0870, Train Acc: 98.38%, Val Loss: 2.4401, Val Acc: 36.28% (Best: 38.05% @ Epoch 31)\n",
      "Epoch 40/50 - Train Loss: 0.0822, Train Acc: 98.82%, Val Loss: 2.4785, Val Acc: 36.73% (Best: 38.05% @ Epoch 31)\n",
      "Epoch 45/50 - Train Loss: 0.0870, Train Acc: 98.38%, Val Loss: 2.4401, Val Acc: 36.28% (Best: 38.05% @ Epoch 31)\n",
      "Epoch 50/50 - Train Loss: 0.0682, Train Acc: 98.97%, Val Loss: 2.4273, Val Acc: 36.73% (Best: 38.05% @ Epoch 31)\n",
      "Final - Best Val Acc: 38.05% @ Epoch 31\n",
      "\n",
      "✓ CLIP + 4-Layer: Best Val 38.05%, Test 33.63%\n",
      "\n",
      "Best CLIP classifier: 2-Layer Val 38.05% Test 33.19%\n",
      "\n",
      "################################################################################\n",
      "STAGE 2 (CLIP): Freeze classifier; unfreeze last N visual blocks and train backbone\n",
      "################################################################################\n",
      "\n",
      "Unfroze last 3 blocks of CLIP visual encoder\n",
      "Epoch 50/50 - Train Loss: 0.0682, Train Acc: 98.97%, Val Loss: 2.4273, Val Acc: 36.73% (Best: 38.05% @ Epoch 31)\n",
      "Final - Best Val Acc: 38.05% @ Epoch 31\n",
      "\n",
      "✓ CLIP + 4-Layer: Best Val 38.05%, Test 33.63%\n",
      "\n",
      "Best CLIP classifier: 2-Layer Val 38.05% Test 33.19%\n",
      "\n",
      "################################################################################\n",
      "STAGE 2 (CLIP): Freeze classifier; unfreeze last N visual blocks and train backbone\n",
      "################################################################################\n",
      "\n",
      "Unfroze last 3 blocks of CLIP visual encoder\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b047422f85734a8f9ca34f63e795683a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Train Epoch 1/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Acc: 17.73% Val Acc: 16.37% (Best: 16.37%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b5ede8d6574820b3ca1129041379ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Train Epoch 2/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Train Acc: 13.29% Val Acc: 15.49% (Best: 16.37%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258aef1417584526ab846666b4e4cc55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Train Epoch 3/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Train Acc: 16.54% Val Acc: 20.80% (Best: 20.80%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dddc4a37c5470e960a59a28dcbfe90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Train Epoch 4/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Train Acc: 26.88% Val Acc: 18.58% (Best: 20.80%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42b65faec4541bba9b40dd288445c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Train Epoch 5/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Acc: 29.69% Val Acc: 25.22% (Best: 25.22%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5703a599a374d70ad0349df01767666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Train Epoch 6/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Train Acc: 31.91% Val Acc: 24.78% (Best: 25.22%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897444fef1f64d28a5186fce7bce4d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Train Epoch 7/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Train Acc: 34.42% Val Acc: 32.74% (Best: 32.74%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2211a14e66254f69a8b819118592e647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Train Epoch 8/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Train Acc: 39.44% Val Acc: 29.65% (Best: 32.74%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4437ad64e3405fb1ab2ff18fcf915d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Train Epoch 9/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Train Acc: 39.59% Val Acc: 36.73% (Best: 36.73%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba399a6824b4867bf031b95837f9182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Train Epoch 10/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Acc: 43.43% Val Acc: 37.61% (Best: 37.61%)\n",
      "\n",
      "Stage 2 (CLIP) complete. Best Val Acc during Stage2: 37.61%\n",
      "Saved CLIP visual Stage2 weights to clip_visual_stage2_finetuned.pth\n"
     ]
    }
   ],
   "source": [
    "# --- CLIP: Retrain classifiers with higher epochs (Stage 1, extended) ---\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"RETRAINING CLIP CLASSIFIERS WITH HIGHER EPOCHS (50)\")\n",
    "print(\"#\"*80 + \"\\n\")\n",
    "\n",
    "clip_stage1_results = []\n",
    "epochs_extended = 50\n",
    "\n",
    "for classifier_name, ClassifierClass in classifier_configs:\n",
    "    print(f\"\\n--- CLIP: Testing {classifier_name} Classifier ---\")\n",
    "\n",
    "    # instantiate\n",
    "    if classifier_name == \"1-Layer\":\n",
    "        classifier = ClassifierClass(clip_dim, num_classes=10)\n",
    "    elif classifier_name == \"2-Layer\":\n",
    "        classifier = ClassifierClass(clip_dim, num_classes=10, hidden_dim=512, dropout=0.3)\n",
    "    elif classifier_name == \"3-Layer\":\n",
    "        classifier = ClassifierClass(clip_dim, num_classes=10, hidden_dim1=512, hidden_dim2=256, dropout=0.3)\n",
    "    else:\n",
    "        classifier = ClassifierClass(clip_dim, num_classes=10, hidden_dims=[512,256,128], dropout=0.3)\n",
    "\n",
    "    trained_clf, best_val_acc, history = train_classifier_on_features(\n",
    "        classifier=classifier,\n",
    "        train_features=clip_train_features,\n",
    "        train_labels=clip_train_labels,\n",
    "        val_features=clip_val_features,\n",
    "        val_labels=clip_val_labels,\n",
    "        epochs=epochs_extended,\n",
    "        lr=1e-3,\n",
    "        batch_size=64\n",
    "    )\n",
    "\n",
    "    test_acc = evaluate_classifier_on_features(trained_clf, clip_test_features, clip_test_labels, batch_size=64)\n",
    "\n",
    "    clip_stage1_results.append({\n",
    "        'classifier': classifier_name,\n",
    "        'model': trained_clf,\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'history': history\n",
    "    })\n",
    "\n",
    "    print(f\"\\n✓ CLIP + {classifier_name}: Best Val {best_val_acc:.2f}%, Test {test_acc:.2f}%\")\n",
    "\n",
    "# pick best CLIP classifier by val acc\n",
    "best_clip = max(clip_stage1_results, key=lambda x: x['best_val_acc'])\n",
    "print(\"\\nBest CLIP classifier:\", best_clip['classifier'], f\"Val {best_clip['best_val_acc']:.2f}% Test {best_clip['test_acc']:.2f}%\")\n",
    "\n",
    "# save to a variable for Stage 2\n",
    "best_clip_classifier = best_clip['model']\n",
    "\n",
    "# --- Stage 2: Partial backbone training for CLIP with frozen classifier ---\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"STAGE 2 (CLIP): Freeze classifier; unfreeze last N visual blocks and train backbone\")\n",
    "print(\"#\"*80 + \"\\n\")\n",
    "\n",
    "# helper to unfreeze last N blocks of CLIP visual transformer\n",
    "def unfreeze_clip_last_n(clip_visual, n=2):\n",
    "    # clip_visual typically has attribute 'transformer.resblocks' or 'blocks'\n",
    "    if hasattr(clip_visual, 'transformer') and hasattr(clip_visual.transformer, 'resblocks'):\n",
    "        blocks = clip_visual.transformer.resblocks\n",
    "    elif hasattr(clip_visual, 'blocks'):\n",
    "        blocks = clip_visual.blocks\n",
    "    else:\n",
    "        raise RuntimeError('Unexpected CLIP visual structure: cannot find transformer blocks')\n",
    "\n",
    "    # freeze all first\n",
    "    for p in clip_visual.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # unfreeze last n blocks\n",
    "    for block in list(blocks)[-n:]:\n",
    "        for p in block.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    # also unfreeze projection head if present\n",
    "    if hasattr(clip_visual, 'proj'):\n",
    "         if isinstance(clip_visual.proj, nn.Parameter):\n",
    "            clip_visual.proj.requires_grad = True\n",
    "        else:\n",
    "            for p in clip_visual.proj.parameters():\n",
    "                p.requires_grad = True\n",
    "    if hasattr(clip_visual, 'ln_post'):\n",
    "        for p in clip_visual.ln_post.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    print(f\"Unfroze last {n} blocks of CLIP visual encoder\")\n",
    "\n",
    "\n",
    "def train_clip_backbone_with_frozen_classifier(clip_visual, classifier, train_loader, val_loader, \n",
    "                                               epochs=10, lr=1e-4, unfreeze_last=2):\n",
    "    device = torch.device('cuda')\n",
    "    classifier = classifier.cuda()\n",
    "    clip_visual = clip_visual.cuda()\n",
    "\n",
    "    # freeze classifier\n",
    "    for p in classifier.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # unfreeze last N\n",
    "    unfreeze_clip_last_n(clip_visual, n=unfreeze_last)\n",
    "\n",
    "    # collect trainable params (from clip_visual)\n",
    "    trainable_params = [p for p in clip_visual.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.AdamW(trainable_params, lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val = 0.0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        clip_visual.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Stage2 Train Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            features = clip_visual(images)\n",
    "            outputs = classifier(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += preds.eq(labels).sum().item()\n",
    "\n",
    "        train_acc = 100.*train_correct/train_total\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # val\n",
    "        clip_visual.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                features = clip_visual(images)\n",
    "                outputs = classifier(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, preds = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += preds.eq(labels).sum().item()\n",
    "\n",
    "        val_acc = 100.*val_correct/val_total\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_model_state = {k: v.cpu() for k, v in clip_visual.state_dict().items()}\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.2f}% Val Acc: {val_acc:.2f}% (Best: {best_val:.2f}%)\")\n",
    "\n",
    "    # load best weights back to device\n",
    "    if best_model_state is not None:\n",
    "        clip_visual.load_state_dict(best_model_state)\n",
    "\n",
    "    return clip_visual, best_val\n",
    "\n",
    "# Run Stage 2 for CLIP\n",
    "unfreeze_last = 3\n",
    "stage2_epochs = 10\n",
    "stage2_lr = 1e-4\n",
    "\n",
    "best_clip_visual_finetuned, best_clip_val = train_clip_backbone_with_frozen_classifier(\n",
    "    clip_visual=clip_visual,\n",
    "    classifier=best_clip_classifier,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=stage2_epochs,\n",
    "    lr=stage2_lr,\n",
    "    unfreeze_last=unfreeze_last\n",
    ")\n",
    "\n",
    "print(f\"\\nStage 2 (CLIP) complete. Best Val Acc during Stage2: {best_clip_val:.2f}%\")\n",
    "\n",
    "# Save the fine-tuned CLIP visual encoder for later stages\n",
    "torch.save(best_clip_visual_finetuned.state_dict(), \"clip_visual_stage2_finetuned.pth\")\n",
    "print(\"Saved CLIP visual Stage2 weights to clip_visual_stage2_finetuned.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a793fe5",
   "metadata": {},
   "source": [
    "## Summary: CLIP Extended Training Complete\n",
    "\n",
    "### Stage 1 Extended (50 epochs)\n",
    "Best CLIP classifier trained on frozen backbone features\n",
    "\n",
    "### Stage 2: Partial Backbone Training\n",
    "- **Approach**: Freeze best classifier, unfreeze last 3 visual transformer blocks\n",
    "- **Strategy**: Train backbone with frozen classification head\n",
    "- **Best Val Accuracy**: 37.61%\n",
    "- **Checkpoint saved**: `clip_visual_stage2_finetuned.pth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae27ffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "open_clip_torch installed\n"
     ]
    }
   ],
   "source": [
    "# Install open_clip_torch (fresh cell to ensure availability)\n",
    "%pip install -q open_clip_torch\n",
    "print('open_clip_torch installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "104d4a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading CLIP Base model (fresh)...\n",
      "✓ CLIP Base reloaded - Feature dimension: 512\n",
      "  Parameters: 86,192,640\n"
     ]
    }
   ],
   "source": [
    "# Reload CLIP model fresh for retraining\n",
    "print(\"Reloading CLIP Base model (fresh)...\")\n",
    "import open_clip\n",
    "\n",
    "clip_model_fresh, _, clip_preprocess_fresh = open_clip.create_model_and_transforms('ViT-B-16', pretrained='openai')\n",
    "clip_model_fresh = clip_model_fresh.cuda()\n",
    "clip_model_fresh.eval()\n",
    "\n",
    "clip_visual_fresh = clip_model_fresh.visual\n",
    "with torch.no_grad():\n",
    "    dummy_input = torch.randn(1, 3, 224, 224).cuda()\n",
    "    clip_features_test = clip_visual_fresh(dummy_input)\n",
    "    clip_dim_fresh = clip_features_test.shape[1]\n",
    "\n",
    "print(f\"✓ CLIP Base reloaded - Feature dimension: {clip_dim_fresh}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in clip_visual_fresh.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "283b03f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RE-EXTRACTING CLIP FEATURES\n",
      "================================================================================\n",
      "Extracting features from CLIP-Base-Fresh...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abba1b3611e9414cbe2e5ae19fa95a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting CLIP-Base-Fresh features:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 677 feature vectors of dim 512\n",
      "Extracting features from CLIP-Base-Fresh...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc5ca21a33f4019924148c9c4be4214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting CLIP-Base-Fresh features:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 226 feature vectors of dim 512\n",
      "Extracting features from CLIP-Base-Fresh...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f1849ed5d04db3841bd4a7fe41578a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting CLIP-Base-Fresh features:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 226 feature vectors of dim 512\n",
      "\n",
      "✓ Fresh CLIP features extracted: torch.Size([677, 512])\n"
     ]
    }
   ],
   "source": [
    "# Extract features from fresh CLIP model\n",
    "print(\"=\"*80)\n",
    "print(\"RE-EXTRACTING CLIP FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "clip_train_features_fresh, _ = extract_features(clip_visual_fresh, train_loader, \"CLIP-Base-Fresh\")\n",
    "clip_val_features_fresh, _ = extract_features(clip_visual_fresh, val_loader, \"CLIP-Base-Fresh\")\n",
    "clip_test_features_fresh, _ = extract_features(clip_visual_fresh, test_loader, \"CLIP-Base-Fresh\")\n",
    "\n",
    "print(f\"\\n✓ Fresh CLIP features extracted: {clip_train_features_fresh.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f871ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "RETRAINING CLIP CLASSIFIERS (50 EPOCHS)\n",
      "################################################################################\n",
      "\n",
      "\n",
      "--- CLIP: Training 1-Layer Classifier ---\n",
      "Epoch 1/50 - Train Loss: 2.2958, Train Acc: 13.59%, Val Loss: 2.2878, Val Acc: 14.60% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 2.2178, Train Acc: 19.79%, Val Loss: 2.3189, Val Acc: 12.83% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 10/50 - Train Loss: 2.1726, Train Acc: 21.42%, Val Loss: 2.3389, Val Acc: 9.29% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 15/50 - Train Loss: 2.1285, Train Acc: 24.67%, Val Loss: 2.3584, Val Acc: 9.73% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 20/50 - Train Loss: 2.0936, Train Acc: 26.59%, Val Loss: 2.3813, Val Acc: 9.29% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 25/50 - Train Loss: 2.0759, Train Acc: 29.10%, Val Loss: 2.3938, Val Acc: 7.96% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 30/50 - Train Loss: 2.0552, Train Acc: 28.80%, Val Loss: 2.4040, Val Acc: 7.52% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 35/50 - Train Loss: 2.0441, Train Acc: 29.84%, Val Loss: 2.4098, Val Acc: 7.96% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 40/50 - Train Loss: 2.0422, Train Acc: 29.99%, Val Loss: 2.4130, Val Acc: 7.52% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 45/50 - Train Loss: 2.0359, Train Acc: 29.99%, Val Loss: 2.4143, Val Acc: 7.52% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 50/50 - Train Loss: 2.0346, Train Acc: 29.99%, Val Loss: 2.4146, Val Acc: 7.96% (Best: 14.60% @ Epoch 1)\n",
      "Final - Best Val Acc: 14.60% @ Epoch 1\n",
      "✓ CLIP + 1-Layer: Val 14.60%, Test 9.29%\n",
      "\n",
      "--- CLIP: Training 2-Layer Classifier ---\n",
      "Epoch 1/50 - Train Loss: 2.4257, Train Acc: 11.08%, Val Loss: 2.3115, Val Acc: 8.41% (Best: 8.41% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 1.4771, Train Acc: 60.27%, Val Loss: 2.6516, Val Acc: 7.96% (Best: 11.06% @ Epoch 2)\n",
      "Epoch 10/50 - Train Loss: 0.8054, Train Acc: 86.41%, Val Loss: 3.0154, Val Acc: 9.73% (Best: 11.06% @ Epoch 2)\n",
      "Epoch 15/50 - Train Loss: 0.3921, Train Acc: 96.75%, Val Loss: 3.5557, Val Acc: 9.29% (Best: 12.39% @ Epoch 12)\n",
      "Epoch 20/50 - Train Loss: 0.2050, Train Acc: 99.70%, Val Loss: 3.9326, Val Acc: 11.95% (Best: 12.39% @ Epoch 12)\n",
      "Epoch 25/50 - Train Loss: 0.1029, Train Acc: 100.00%, Val Loss: 4.1159, Val Acc: 9.73% (Best: 12.39% @ Epoch 12)\n",
      "Epoch 30/50 - Train Loss: 0.0728, Train Acc: 100.00%, Val Loss: 4.4585, Val Acc: 8.85% (Best: 12.39% @ Epoch 12)\n",
      "Epoch 35/50 - Train Loss: 0.0569, Train Acc: 100.00%, Val Loss: 4.5157, Val Acc: 9.73% (Best: 12.39% @ Epoch 12)\n",
      "Epoch 40/50 - Train Loss: 0.0507, Train Acc: 100.00%, Val Loss: 4.5319, Val Acc: 10.18% (Best: 12.39% @ Epoch 12)\n",
      "Epoch 45/50 - Train Loss: 0.0499, Train Acc: 100.00%, Val Loss: 4.5829, Val Acc: 9.73% (Best: 12.39% @ Epoch 12)\n",
      "Epoch 50/50 - Train Loss: 0.0452, Train Acc: 100.00%, Val Loss: 4.5797, Val Acc: 9.29% (Best: 12.39% @ Epoch 12)\n",
      "Final - Best Val Acc: 12.39% @ Epoch 12\n",
      "✓ CLIP + 2-Layer: Val 12.39%, Test 13.27%\n",
      "\n",
      "--- CLIP: Training 3-Layer Classifier ---\n",
      "Epoch 1/50 - Train Loss: 2.3747, Train Acc: 11.67%, Val Loss: 2.2933, Val Acc: 14.60% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 1.6316, Train Acc: 48.01%, Val Loss: 2.4902, Val Acc: 9.29% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 10/50 - Train Loss: 0.8938, Train Acc: 79.17%, Val Loss: 2.8661, Val Acc: 9.29% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 15/50 - Train Loss: 0.3910, Train Acc: 93.94%, Val Loss: 3.6362, Val Acc: 11.95% (Best: 14.60% @ Epoch 1)\n",
      "Epoch 20/50 - Train Loss: 0.1802, Train Acc: 98.08%, Val Loss: 3.9091, Val Acc: 11.06% (Best: 15.49% @ Epoch 16)\n",
      "Epoch 25/50 - Train Loss: 0.1137, Train Acc: 98.82%, Val Loss: 3.9043, Val Acc: 12.83% (Best: 15.49% @ Epoch 16)\n",
      "Epoch 30/50 - Train Loss: 0.0661, Train Acc: 99.70%, Val Loss: 4.0504, Val Acc: 11.50% (Best: 15.49% @ Epoch 16)\n",
      "Epoch 35/50 - Train Loss: 0.0520, Train Acc: 99.70%, Val Loss: 4.2050, Val Acc: 11.95% (Best: 15.49% @ Epoch 16)\n",
      "Epoch 40/50 - Train Loss: 0.0436, Train Acc: 99.70%, Val Loss: 4.2911, Val Acc: 12.39% (Best: 15.49% @ Epoch 16)\n",
      "Epoch 45/50 - Train Loss: 0.0414, Train Acc: 99.56%, Val Loss: 4.2935, Val Acc: 12.39% (Best: 15.49% @ Epoch 16)\n",
      "Epoch 50/50 - Train Loss: 0.0368, Train Acc: 99.70%, Val Loss: 4.2606, Val Acc: 11.95% (Best: 15.49% @ Epoch 16)\n",
      "Final - Best Val Acc: 15.49% @ Epoch 16\n",
      "✓ CLIP + 3-Layer: Val 15.49%, Test 12.39%\n",
      "\n",
      "--- CLIP: Training 4-Layer Classifier ---\n",
      "Epoch 1/50 - Train Loss: 2.3755, Train Acc: 10.93%, Val Loss: 2.3063, Val Acc: 11.50% (Best: 11.50% @ Epoch 1)\n",
      "Epoch 5/50 - Train Loss: 1.9777, Train Acc: 31.17%, Val Loss: 2.4101, Val Acc: 9.29% (Best: 11.95% @ Epoch 2)\n",
      "Epoch 10/50 - Train Loss: 1.4358, Train Acc: 57.02%, Val Loss: 2.7048, Val Acc: 9.29% (Best: 11.95% @ Epoch 2)\n",
      "Epoch 15/50 - Train Loss: 0.9347, Train Acc: 73.86%, Val Loss: 2.8832, Val Acc: 11.06% (Best: 11.95% @ Epoch 2)\n",
      "Epoch 20/50 - Train Loss: 0.5651, Train Acc: 85.08%, Val Loss: 3.1410, Val Acc: 11.06% (Best: 11.95% @ Epoch 2)\n",
      "Epoch 25/50 - Train Loss: 0.3508, Train Acc: 92.47%, Val Loss: 3.3181, Val Acc: 13.27% (Best: 13.27% @ Epoch 25)\n",
      "Epoch 30/50 - Train Loss: 0.2282, Train Acc: 95.86%, Val Loss: 3.3648, Val Acc: 11.06% (Best: 15.04% @ Epoch 27)\n",
      "Epoch 35/50 - Train Loss: 0.1480, Train Acc: 98.38%, Val Loss: 3.6159, Val Acc: 12.39% (Best: 15.04% @ Epoch 27)\n",
      "Epoch 40/50 - Train Loss: 0.1419, Train Acc: 97.64%, Val Loss: 3.5666, Val Acc: 11.95% (Best: 15.04% @ Epoch 27)\n",
      "Epoch 45/50 - Train Loss: 0.1205, Train Acc: 99.41%, Val Loss: 3.6159, Val Acc: 11.95% (Best: 15.04% @ Epoch 27)\n",
      "Epoch 50/50 - Train Loss: 0.1268, Train Acc: 98.08%, Val Loss: 3.6366, Val Acc: 11.50% (Best: 15.04% @ Epoch 27)\n",
      "Final - Best Val Acc: 15.04% @ Epoch 27\n",
      "✓ CLIP + 4-Layer: Val 15.04%, Test 11.95%\n",
      "\n",
      "================================================================================\n",
      "Best CLIP Classifier: 3-Layer\n",
      "  Val: 15.49%\n",
      "  Test: 12.39%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Retrain CLIP classifiers (Stage 1 with 50 epochs)\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"RETRAINING CLIP CLASSIFIERS (50 EPOCHS)\")\n",
    "print(\"#\"*80 + \"\\n\")\n",
    "\n",
    "clip_stage1_retrain = []\n",
    "\n",
    "for classifier_name, ClassifierClass in classifier_configs:\n",
    "    print(f\"\\n--- CLIP: Training {classifier_name} Classifier ---\")\n",
    "\n",
    "    if classifier_name == \"1-Layer\":\n",
    "        classifier = ClassifierClass(clip_dim_fresh, num_classes=10)\n",
    "    elif classifier_name == \"2-Layer\":\n",
    "        classifier = ClassifierClass(clip_dim_fresh, num_classes=10, hidden_dim=512, dropout=0.3)\n",
    "    elif classifier_name == \"3-Layer\":\n",
    "        classifier = ClassifierClass(clip_dim_fresh, num_classes=10, hidden_dim1=512, hidden_dim2=256, dropout=0.3)\n",
    "    else:\n",
    "        classifier = ClassifierClass(clip_dim_fresh, num_classes=10, hidden_dims=[512,256,128], dropout=0.3)\n",
    "\n",
    "    trained_clf, best_val_acc, history = train_classifier_on_features(\n",
    "        classifier=classifier,\n",
    "        train_features=clip_train_features_fresh,\n",
    "        train_labels=clip_train_labels,\n",
    "        val_features=clip_val_features_fresh,\n",
    "        val_labels=clip_val_labels,\n",
    "        epochs=50,\n",
    "        lr=1e-3,\n",
    "        batch_size=64\n",
    "    )\n",
    "\n",
    "    test_acc = evaluate_classifier_on_features(trained_clf, clip_test_features_fresh, clip_test_labels, batch_size=64)\n",
    "\n",
    "    clip_stage1_retrain.append({\n",
    "        'classifier': classifier_name,\n",
    "        'model': trained_clf,\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'history': history\n",
    "    })\n",
    "\n",
    "    print(f\"✓ CLIP + {classifier_name}: Val {best_val_acc:.2f}%, Test {test_acc:.2f}%\")\n",
    "\n",
    "# Select best\n",
    "best_clip_retrain = max(clip_stage1_retrain, key=lambda x: x['best_val_acc'])\n",
    "best_clip_classifier_retrain = best_clip_retrain['model']\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Best CLIP Classifier: {best_clip_retrain['classifier']}\")\n",
    "print(f\"  Val: {best_clip_retrain['best_val_acc']:.2f}%\")\n",
    "print(f\"  Test: {best_clip_retrain['test_acc']:.2f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c778c38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "CLIP STAGE 2: PARTIAL BACKBONE TRAINING (RETRAIN)\n",
      "################################################################################\n",
      "\n",
      "Unfroze last 3 blocks of CLIP visual encoder\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4ec936f0e24f56bbce3357e121bfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Epoch 1/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train: 9.90%, Val: 7.96% (Best: 7.96%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9de79c8ca924d5f989119bb7b0a52bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Epoch 2/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Train: 14.18%, Val: 12.83% (Best: 12.83%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b289e6a32a4f6d82f878234cedf1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Epoch 3/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Train: 17.28%, Val: 16.37% (Best: 16.37%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe39a612fb794066b1c2a99d7f7d3542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Epoch 4/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Train: 24.22%, Val: 20.35% (Best: 20.35%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f696cb6326f644c984902344f26cb573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Epoch 5/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train: 24.08%, Val: 31.86% (Best: 31.86%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111c4eeda7ed4632970008ff6cf9525d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Epoch 6/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Train: 32.79%, Val: 29.65% (Best: 31.86%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1eda61e7eb4deb8f9f60121b14df5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Epoch 7/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Train: 33.53%, Val: 30.53% (Best: 31.86%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b90bb4d6b6b406ebba2569bf1321de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Epoch 8/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Train: 34.71%, Val: 31.42% (Best: 31.86%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715acf8127f340f194f52b3f7cc68032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Epoch 9/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Train: 37.37%, Val: 31.42% (Best: 31.86%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7072b7173444170b0a851e061aeb057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stage2 Epoch 10/10:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train: 39.14%, Val: 32.74% (Best: 32.74%)\n",
      "\n",
      "================================================================================\n",
      "CLIP STAGE 2 COMPLETE (RETRAIN)\n",
      "Best Val Acc: 32.74%\n",
      "================================================================================\n",
      "Saved: clip_visual_stage2_retrain.pth, clip_classifier_best_retrain.pth\n"
     ]
    }
   ],
   "source": [
    "# Stage 2: Partial backbone training for CLIP (retrain)\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"CLIP STAGE 2: PARTIAL BACKBONE TRAINING (RETRAIN)\")\n",
    "print(\"#\"*80 + \"\\n\")\n",
    "\n",
    "# helper to unfreeze last N blocks\n",
    "def unfreeze_clip_last_n_v2(clip_visual, n=2):\n",
    "    if hasattr(clip_visual, 'transformer') and hasattr(clip_visual.transformer, 'resblocks'):\n",
    "        blocks = clip_visual.transformer.resblocks\n",
    "    elif hasattr(clip_visual, 'blocks'):\n",
    "        blocks = clip_visual.blocks\n",
    "    else:\n",
    "        raise RuntimeError('Cannot find CLIP transformer blocks')\n",
    "\n",
    "    # freeze all\n",
    "    for p in clip_visual.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # unfreeze last n blocks\n",
    "    for block in list(blocks)[-n:]:\n",
    "        for p in block.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    # unfreeze projection\n",
    "    if hasattr(clip_visual, 'proj'):\n",
    "        if isinstance(clip_visual.proj, nn.Parameter):\n",
    "            clip_visual.proj.requires_grad = True\n",
    "        else:\n",
    "            for p in clip_visual.proj.parameters():\n",
    "                p.requires_grad = True\n",
    "    if hasattr(clip_visual, 'ln_post'):\n",
    "        for p in clip_visual.ln_post.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    print(f\"Unfroze last {n} blocks of CLIP visual encoder\")\n",
    "\n",
    "\n",
    "def train_clip_stage2_v2(clip_visual, classifier, train_loader, val_loader, \n",
    "                         epochs=10, lr=1e-4, unfreeze_last=3):\n",
    "    device = torch.device('cuda')\n",
    "    classifier = classifier.cuda()\n",
    "    clip_visual = clip_visual.cuda()\n",
    "\n",
    "    # freeze classifier\n",
    "    for p in classifier.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # unfreeze last N\n",
    "    unfreeze_clip_last_n_v2(clip_visual, n=unfreeze_last)\n",
    "\n",
    "    # trainable params\n",
    "    trainable_params = [p for p in clip_visual.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.AdamW(trainable_params, lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val = 0.0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        clip_visual.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Stage2 Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            features = clip_visual(images)\n",
    "            outputs = classifier(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += preds.eq(labels).sum().item()\n",
    "\n",
    "        train_acc = 100.*train_correct/train_total\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # val\n",
    "        clip_visual.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                features = clip_visual(images)\n",
    "                outputs = classifier(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, preds = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += preds.eq(labels).sum().item()\n",
    "\n",
    "        val_acc = 100.*val_correct/val_total\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_model_state = {k: v.cpu().clone() for k, v in clip_visual.state_dict().items()}\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train: {train_acc:.2f}%, Val: {val_acc:.2f}% (Best: {best_val:.2f}%)\")\n",
    "\n",
    "    # restore best\n",
    "    if best_model_state is not None:\n",
    "        clip_visual.load_state_dict(best_model_state)\n",
    "        clip_visual = clip_visual.cuda()\n",
    "\n",
    "    return clip_visual, best_val\n",
    "\n",
    "\n",
    "# Run Stage 2\n",
    "clip_visual_stage2_retrain, best_val_stage2_retrain = train_clip_stage2_v2(\n",
    "    clip_visual=clip_visual_fresh,\n",
    "    classifier=best_clip_classifier_retrain,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=10,\n",
    "    lr=1e-4,\n",
    "    unfreeze_last=3\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"CLIP STAGE 2 COMPLETE (RETRAIN)\")\n",
    "print(f\"Best Val Acc: {best_val_stage2_retrain:.2f}%\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Save checkpoint\n",
    "torch.save(clip_visual_stage2_retrain.state_dict(), \"clip_visual_stage2_retrain.pth\")\n",
    "torch.save(best_clip_classifier_retrain.state_dict(), \"clip_classifier_best_retrain.pth\")\n",
    "print(\"Saved: clip_visual_stage2_retrain.pth, clip_classifier_best_retrain.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a730623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoints for all trained models\n",
    "import os\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "saved = []\n",
    "\n",
    "def _safe_save(model, path):\n",
    "    try:\n",
    "        state = model.state_dict()\n",
    "        # move tensors to CPU to avoid device issues\n",
    "        state_cpu = {k: v.cpu() for k, v in state.items()}\n",
    "        torch.save(state_cpu, path)\n",
    "        print(f\"Saved: {path}\")\n",
    "        saved.append(path)\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            # if it's already a state dict\n",
    "            torch.save(model, path)\n",
    "            print(f\"Saved (fallback): {path}\")\n",
    "            saved.append(path)\n",
    "        except Exception as e2:\n",
    "            print(f\"Failed to save {path}: {e} | {e2}\")\n",
    "\n",
    "# 1) Save classifiers from stage1_results (if present)\n",
    "if 'stage1_results' in globals():\n",
    "    for r in stage1_results:\n",
    "        backbone = r.get('backbone', 'backbone').replace(' ', '')\n",
    "        clf_name = r.get('classifier', 'clf').replace(' ', '')\n",
    "        model = r.get('model', None)\n",
    "        if model is not None:\n",
    "            fname = f\"checkpoints/stage1_{backbone}_{clf_name}.pth\"\n",
    "            _safe_save(model, fname)\n",
    "\n",
    "# 2) Save CLIP stage1 results (if present)\n",
    "if 'clip_stage1_results' in globals():\n",
    "    for r in clip_stage1_results:\n",
    "        clf_name = r.get('classifier', 'clf').replace(' ', '')\n",
    "        model = r.get('model', None)\n",
    "        if model is not None:\n",
    "            fname = f\"checkpoints/clip_stage1_{clf_name}.pth\"\n",
    "            _safe_save(model, fname)\n",
    "\n",
    "# 3) Save CLIP retrain classifiers\n",
    "if 'clip_stage1_retrain' in globals():\n",
    "    for r in clip_stage1_retrain:\n",
    "        clf_name = r.get('classifier', 'clf').replace(' ', '')\n",
    "        model = r.get('model', None)\n",
    "        if model is not None:\n",
    "            fname = f\"checkpoints/clip_retrain_{clf_name}.pth\"\n",
    "            _safe_save(model, fname)\n",
    "\n",
    "# 4) Save best clip classifiers if defined\n",
    "for varname in ['best_clip_classifier', 'best_clip_classifier_retrain', 'trained_classifier', 'trained_clf', 'trained_clf_retrain']:\n",
    "    if varname in globals():\n",
    "        try:\n",
    "            _safe_save(globals()[varname], f\"checkpoints/{varname}.pth\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# 5) Save fine-tuned visual encoders if available\n",
    "for varname, fname in [\n",
    "    ('best_clip_visual_finetuned', 'checkpoints/clip_visual_stage2_finetuned.pth'),\n",
    "    ('clip_visual_stage2_retrain', 'checkpoints/clip_visual_stage2_retrain.pth'),\n",
    "    ('dinov2_small', 'checkpoints/dinov2_small_base.pth')\n",
    "]:\n",
    "    if varname in globals():\n",
    "        model = globals()[varname]\n",
    "        # don't overwrite dinov2 pretrained weights; save only if modified\n",
    "        if varname == 'dinov2_small':\n",
    "            # save state dict of backbone (may be pretrained) for reproducibility\n",
    "            _safe_save(model, fname)\n",
    "        else:\n",
    "            _safe_save(model, fname)\n",
    "\n",
    "# 6) Save any explicitly saved filenames created earlier\n",
    "for filename in ['clip_visual_stage2_finetuned.pth', 'clip_visual_stage2_retrain.pth', 'clip_classifier_best_retrain.pth']:\n",
    "    if os.path.exists(filename):\n",
    "        dest = os.path.join('checkpoints', filename)\n",
    "        if not os.path.exists(dest):\n",
    "            try:\n",
    "                import shutil\n",
    "                shutil.copy2(filename, dest)\n",
    "                print(f\"Copied {filename} to {dest}\")\n",
    "                saved.append(dest)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to copy {filename}: {e}\")\n",
    "\n",
    "print('\\nAll checkpoint save attempts finished.')\n",
    "print('Files saved:', saved)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
